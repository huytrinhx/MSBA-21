{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Week4_shell.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"lMLCYV4OheUC"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EulLAzlnhuzM"},"source":["## Change these variables when running the notebook from a new location\n","# data_dir should be the directory of the zip files\n","# pickle_input should be the location of the 201516_ret.pickle file\n","\n","root_dir = \"/content/drive/My Drive/BVIA Group 4/\"\n","data_dir = root_dir + \"Data/\"\n","pickle_input_201516 = root_dir + \"Pickle/201516_ret.pickle\"\n","pickle_input_201213 = root_dir + \"Pickle/201213_ret.pickle\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"Dmzy3cYEhSps"},"source":["# Week 4 - Picking Loans using Regression of Loan Returns\n","\n","This notebook carries out the following steps\n","  1. Reads the saved pickle data. Re-run the classification models and check their stability over time\n","  2. Using only variables available at the time of loan application, predicts the returns on the loans\n","  3. Uses the regressions for returns and the classification models from before for implementimg some simple strategies for picking loans to invest in. \n","  4. Tests these strategies on a portfolio of 100 loans\n","  5. Re-run the test strategies on different test and train sets from different time periods\n","  6. Performs a sensitivity analysis of the performance of the loan to the number of loans invested in from 100 to 1000"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true,"id":"VdYjeUAjhSpt","executionInfo":{"status":"ok","timestamp":1601346093359,"user_tz":300,"elapsed":2779,"user":{"displayName":"Huy Trinh","photoUrl":"","userId":"02499034731944614649"}},"outputId":"13727f26-da17-4528-fe2b-c7f7a1712b00","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# Load general utilities\n","# ----------------------\n","import pandas as pd\n","import pickle \n","import matplotlib.pyplot as plt\n","import matplotlib.axes as ax\n","import datetime\n","import numpy as np\n","import pickle\n","import time\n","import seaborn as sns\n","import random\n","import plotly.express as px\n","\n","# Load sklearn utilities\n","# ----------------------\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, brier_score_loss, mean_squared_error, r2_score\n","\n","from sklearn.calibration import calibration_curve\n","\n","# Load classifiers\n","# ----------------\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import BaggingClassifier\n","\n","# Other Packages\n","# --------------\n","from scipy.stats import kendalltau\n","from sklearn.neural_network import MLPRegressor\n","from sklearn import linear_model\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.cluster import KMeans\n","## from gurobipy import *\n","from sklearn.externals.six import StringIO  \n","from IPython.display import Image  \n","from sklearn.tree import export_graphviz\n","import pydotplus\n","#from scipy.interpolate import spline\n","\n","# Load debugger, if required\n","#import pixiedust\n","pd.options.mode.chained_assignment = None #'warn'\n","\n","# suppress all warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning:\n","\n","The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ZGn_kNP6hSpx","executionInfo":{"status":"error","timestamp":1601346093914,"user_tz":300,"elapsed":3312,"user":{"displayName":"Huy Trinh","photoUrl":"","userId":"02499034731944614649"}},"outputId":"3ec6ca1d-50d3-412a-9543-b5a5ac60026d","colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["# read saved models after you have run some of the more time consuming ones and saved them\n","path = root_dir + \"/saved_models/week4_saved_models\"   \n","infile = open(path,'rb')\n","saved_models = pickle.load(infile)\n","models_to_save = saved_models.copy() # save new models in this new dict\n","infile.close()\n","print('models loaded:\\n', saved_models.keys())"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-fa2c1660cb3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read saved models after you have run some of the more time consuming ones and saved them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/saved_models/week4_saved_models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msaved_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodels_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save new models in this new dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BVIA Group 4//saved_models/week4_saved_models'"]}]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"o0GP0_PYhSp0"},"source":["# Define a function that, given a CVGridSearch object, finds the\n","# percentage difference between the best and worst scores\n","def find_score_variation(cv_model):\n","    all_scores = cv_model.cv_results_['mean_test_score']\n","    return( np.abs((max(all_scores) - min(all_scores))) * 100 / max(all_scores) )\n","\n","    '''\n","    which_min_score = np.argmin(all_scores)\n","    \n","    all_perc_diff = []\n","    \n","    try:\n","        all_perc_diff.append( np.abs(all_scores[which_min_score - 1] - all_scores[which_min_score])*100 / min(all_scores) )\n","    except:\n","        pass\n","    \n","    try:\n","        all_perc_diff.append( np.abs(all_scores[which_min_score + 1] - all_scores[which_min_score])*100 / min(all_scores) )\n","    except:\n","        pass\n","    \n","    return ( np.mean(all_perc_diff) )\n","    '''\n","\n","# Define a function that checks, given a CVGridSearch object,\n","# whether the optimal parameters lie on the edge of the search\n","# grid\n","def find_opt_params_on_edge(cv_model):\n","    out = False\n","    \n","    for i in cv_model.param_grid:\n","        if cv_model.best_params_[i] in [ cv_model.param_grid[i][0], cv_model.param_grid[i][-1] ]:\n","            out = True\n","            break\n","            \n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"yflWEcMZhSp2"},"source":["## Define a default random seed and an output file"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"cyNBibt_hSp3"},"source":["default_seed = 1\n","output_file = \"output_sample\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"tDoiwOmzhSp6"},"source":["# Create a function to print a line to our output file\n","def dump_to_output(key, value):\n","    with open(output_file, \"a\") as f:\n","        f.write(\",\".join([str(default_seed), key, str(value)]) + \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehp0-leS4d97"},"source":["## 0.05 Downsample function"]},{"cell_type":"markdown","metadata":{"id":"KhlVZwvrjjR8"},"source":["The following functions are used to downsample the loans to make them class-balance."]},{"cell_type":"code","metadata":{"id":"hxnIW5HS64Ev"},"source":["def returnCounts(data):\n","  TCount = len(data)\n","  FCount = data.loan_status.str.contains('Fully Paid').sum()\n","  CCount = data.loan_status.str.contains('Charged Off').sum()\n","  DCount = data.loan_status.str.contains('Default').sum()\n","  DProp = 1-(FCount/TCount)\n","\n","  print(\"Total count: %d\" %(TCount))\n","  print(\"Fully Paid count: %d\" %(FCount))\n","  print(\"Charged off count: %d\" %(CCount))\n","  print(\"Default count: %d\" %(DCount))\n","  print(\"Proportion of Charged off + Default: %.2f\" %(DProp))\n","  return TCount, FCount, CCount, DCount, DProp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LK3-1EN4kL6"},"source":["def downsample(data, delProp = 0.7):\n","  dataCopy = data.copy()\n","  indexNames = dataCopy[dataCopy['loan_status'] == \"Fully Paid\" ].index #pull indexes of fully paid rows\n","  \n","  print(\"Before downsample:\")\n","  TCount, FCount, CCount, DCount, DProp = returnCounts(dataCopy)\n","\n","  delRowCount = int(delProp*FCount) \n","  random.seed(4)\n","  dataCopy=dataCopy.drop(random.sample(set(indexNames), delRowCount)) #remove ~70% of the 'fully paid' entries\n","\n","  print(\"\\nAfter downsample:\")\n","  TCount, FCount, CCount, DCount, DProp = returnCounts(dataCopy)\n","\n","  return dataCopy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"Hws2EK_9hSp8"},"source":["## 0.1 Load the data (2012-2013) and engineer the features"]},{"cell_type":"code","metadata":{"id":"8kdZ6AzLhSp8"},"source":["# Read the data and features from the pickle\n","data12, discrete_features, continuous_features, ret_cols = pickle.load( open( pickle_input_201213, \"rb\" ) )\n","\n","#data = data12.copy()\n","data = downsample(data12, delProp = 0.75)\n","\n","# Create the outcome\n","data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n","\n","# Create a feature for the length of a person's credit history at the\n","# time the loan is issued\n","data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n","continuous_features.append('cr_hist')\n","\n","\n","# Randomly assign each row to a training and test set. We do this now\n","# because we will be fitting a variety of models on various time periods,\n","# and we would like every period to use the *same* training/test split\n","np.random.seed(default_seed)\n","data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])\n","\n","# Create a matrix of features and outcomes, with dummies. Record the\n","# names of the dummies for later use\n","X_continuous = data[continuous_features].values\n","\n","X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n","discrete_features_dummies = X_discrete.columns.tolist()\n","X_discrete = X_discrete.values\n","\n","X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n","\n","y = data.outcome.values\n","\n","train = data.train.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tj1M1r1GM4-0"},"source":["## STORE PROPORTION OF DEFAULT\n","train_default = 0.43\n","train_not_default = 0.57\n","\n","actual_default = 0.16\n","actual_not_default = 0.84"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"68OEXwWEhSp-"},"source":["## 0.2 Prepare functions to fit and evaluate models"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"wgBdTzs3hSp_"},"source":["def prepare_data(data_subset = np.array([True]*len(data)),\n","                    n_samples_train = 20000,\n","                    n_samples_test = 10000,\n","                    feature_subset = None,\n","                    date_range_train = (data.issue_d.min(), data.issue_d.max()),\n","                    date_range_test = (data.issue_d.min(), data.issue_d.max()),\n","                    random_state = default_seed):\n","    '''\n","    This function will prepare the data for classification or regression.\n","    It expects the following parameters:\n","      - data_subset: a numpy array with as many entries as rows in the\n","                     dataset. Each entry should be True if that rowFdecisipn\n","                     should be used, or False if it should be ignored\n","      - n_samples_train: the total number of samples to be used for training.\n","                         Will trigger an error if this number is larger than\n","                         the number of rows available after all filters have\n","                         been applied\n","      - n_samples_test: as above for testing\n","      - feature_subect: A list containing the names of the features to be\n","                        used in the model. In None, all features in X are\n","                        used\n","      - date_range_train: a tuple containing two dates. All rows with loans\n","                          issued outside of these two dates will be ignored in\n","                          training\n","      - date_range_test: as above for testing\n","      - random_state: the random seed to use when selecting a subset of rows\n","      \n","    Note that this function assumes the data has a \"Train\" column, and will\n","    select all training rows from the rows with \"True\" in that column, and all\n","    the testing rows from those with a \"False\" in that column.\n","    \n","    This function returns a dictionary with the following entries\n","      - X_train: the matrix of training data\n","      - y_train: the array of training labels\n","      - train_set: a Boolean vector with as many entries as rows in the data\n","                  that denotes the rows that were used in the train set\n","      - X_test: the matrix of testing data\n","      - y_test: the array of testing labels\n","      - test_set: a Boolean vector with as many entries as rows in the data\n","                  that denotes the rows that were used in the test set\n","    '''\n","    \n","    np.random.seed(random_state)\n","    \n","    # Filter down the data to the required date range, and downsample\n","    # as required\n","#     print(\"sizes:\", train.shape[0], data.shape[0], data_subset.shape[0])\n","    filter_train = ( train & (data.issue_d >= date_range_train[0]) &\n","                            (data.issue_d <= date_range_train[1]) & data_subset ).values\n","    filter_test = ( (train == False) & (data.issue_d >= date_range_test[0])\n","                            & (data.issue_d <= date_range_test[1]) & data_subset ).values\n","    \n","    filter_train[ np.random.choice( np.where(filter_train)[0], size = filter_train.sum() \n","                                   - n_samples_train, replace = False ) ] = False\n","    filter_test[ np.random.choice( np.where(filter_test)[0], size = filter_test.sum() \n","                                   - n_samples_test, replace = False ) ] = False\n","    \n","    # Prepare the training and test set\n","    X_train = X[ filter_train , :]\n","    X_test = X[ filter_test, :]\n","    if feature_subset != None:\n","        cols = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in feature_subset]\n","        X_train = X_train[ : , cols ]\n","        X_test = X_test[ : , cols ]\n","        \n","    y_train = y[ filter_train ]\n","    y_test = y[ filter_test ]\n","    \n","    # Scale the variables\n","    scaler = preprocessing.MinMaxScaler()\n","\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    \n","    # return training and testing data\n","    out = {'X_train':X_train, 'y_train':y_train, 'train_set':filter_train, \n","           'X_test':X_test, 'y_test':y_test, 'test_set':filter_test}\n","    \n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"k3g6PH67hSqC"},"source":["def fit_classification(model, data_dict,\n","                          cv_parameters = {},\n","                          model_name = None,\n","                          random_state = default_seed,\n","                          output_to_file = True,\n","                          print_to_screen = True):\n","    '''\n","    This function will fit a classification model to data and print various evaluation\n","    measures. It expects the following parameters\n","      - model: an sklearn model object\n","      - data_dict: the dictionary containing both training and testing data;\n","                   returned by the prepare_data function\n","      - cv_parameters: a dictionary of parameters that should be optimized\n","                       over using cross-validation. Specifically, each named\n","                       entry in the dictionary should correspond to a parameter,\n","                       and each element should be a list containing the values\n","                       to optimize over\n","      - model_name: the name of the model being fit, for printouts\n","      - random_state: the random seed to use\n","      - output_to_file: if the results will be saved to the output file\n","      - print_to_screen: if the results will be printed on screen\n","    \n","    If the model provided does not have a predict_proba function, we will\n","    simply print accuracy diagnostics and return.\n","    \n","    If the model provided does have a predict_proba function, we first\n","    figure out the optimal threshold that maximizes the accuracy and\n","    print out accuracy diagnostics. We then print an ROC curve, sensitivity/\n","    specificity curve, and calibration curve.\n","    \n","    This function returns a dictionary with the following entries\n","      - model: the best fitted model\n","      - y_pred: predictions for the test set\n","      - y_pred_probs: probability predictions for the test set, if the model\n","                      supports them\n","      - y_pred_score: prediction scores for the test set, if the model does not \n","                      output probabilities.\n","    '''\n","        \n","    np.random.seed(random_state)\n","    \n","    # --------------------------\n","    #   Step 1 - Load the data\n","    # --------------------------\n","    X_train = data_dict['X_train']\n","    y_train = data_dict['y_train']\n","    \n","    X_test = data_dict['X_test']\n","    y_test = data_dict['y_test']\n","    \n","    filter_train = data_dict['train_set']    \n","  \n","    # --------------------------\n","    #   Step 2 - Fit the model\n","    # --------------------------\n","\n","    cv_model = GridSearchCV(model, cv_parameters)\n","    \n","    start_time = time.time()\n","    cv_model.fit(X_train, y_train)\n","    end_time = time.time()\n","    \n","    best_model = cv_model.best_estimator_\n","    \n","    if print_to_screen:\n","\n","        if model_name != None:\n","            print(\"=========================================================\")\n","            print(\"  Model: \" + model_name)\n","            print(\"=========================================================\")\n","\n","        print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n","        print(\"Optimal parameters:\")\n","        print(cv_model.best_params_)\n","        print(\"\")\n","    \n","    # -------------------------------\n","    #   Step 3 - Evaluate the model\n","    # -------------------------------\n","    \n","    # If possible, make probability predictions\n","    try:\n","        y_pred_probs = best_model.predict_proba(X_test)[:,1]\n","        fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n","        \n","        probs_predicted = True\n","    except:\n","        probs_predicted = False\n","    \n","    # Make predictions; if we were able to find probabilities, use\n","    # the threshold that maximizes the accuracy in the training set.\n","    # If not, just use the learner's predict function\n","    if probs_predicted:\n","        y_train_pred_probs = best_model.predict_proba(X_train)[:,1]\n","        fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_pred_probs)\n","        \n","        true_pos_train = tpr_train*(y_train.sum())\n","        true_neg_train = (1 - fpr_train) *(1-y_train).sum()\n","        \n","        best_threshold_index = np.argmax(true_pos_train + true_neg_train)\n","        best_threshold = 1 if best_threshold_index == 0 else thresholds_train[ best_threshold_index ]\n","        \n","        if print_to_screen:\n","            print(\"Accuracy-maximizing threshold was: \" + str(best_threshold))\n","        \n","        y_pred = (y_pred_probs > best_threshold)\n","    else:\n","        y_pred = best_model.predict(X_test)\n","    \n","    if print_to_screen:\n","        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n","        print(classification_report(y_test, y_pred, target_names =['No default', 'Default'], digits = 4))\n","\n","    if print_to_screen:\n","        if probs_predicted:        \n","            plt.figure(figsize = (13, 4.5))\n","            plt.subplot(2, 2, 1)\n","\n","            plt.title(\"ROC Curve (AUC = %0.2f)\"% roc_auc_score(y_test, y_pred_probs))\n","            plt.plot(fpr, tpr, 'b')\n","            plt.plot([0,1],[0,1],'r--')\n","            plt.xlim([0,1]); plt.ylim([0,1])\n","            plt.ylabel('True Positive Rate')\n","            plt.xlabel('False Positive Rate')\n","\n","            plt.subplot(2, 2, 3)\n","\n","            plt.plot(thresholds, tpr, 'b', label = 'Sensitivity')\n","            plt.plot(thresholds, 1 -fpr, 'r', label = 'Specificity')\n","            plt.legend(loc = 'lower right')\n","            plt.xlim([0,1]); plt.ylim([0,1])\n","            plt.xlabel('Threshold')\n","\n","            plt.subplot(2, 2, 2)\n","\n","            fp_0, mpv_0 = calibration_curve(y_test, y_pred_probs, n_bins = 10)\n","            plt.plot([0,1], [0,1], 'k:', label='Perfectly calibrated')\n","            plt.plot(mpv_0, fp_0, 's-')\n","            plt.ylabel('Fraction of Positives')\n","            plt.xlim([0,1]); plt.ylim([0,1])\n","            plt.legend(loc ='upper left')\n","            \n","            plt.subplot(2, 2, 4)\n","            plt.hist(y_pred_probs, range=(0, 1), bins=10, histtype=\"step\", lw=2)\n","            plt.xlim([0,1]); plt.ylim([0,20000])\n","            plt.xlabel('Mean Predicted Probability')\n","            plt.ylabel('Count')\n","            \n","            #plt.tight_layout()\n","            plt.show()\n","        \n","    # Additional Score Check\n","    if probs_predicted:\n","        y_train_score = y_train_pred_probs\n","    else:\n","        y_train_score = best_model.decision_function(X_train)\n","        \n","    tau, p_value = kendalltau(y_train_score, data.grade[filter_train])\n","    if print_to_screen:\n","        print(\"\")\n","        print(\"Similarity to LC grade ranking: \", tau)\n","    \n","    if probs_predicted:\n","        brier_score = brier_score_loss(y_test, y_pred_probs)\n","        if print_to_screen:\n","            print(\"Brier score:\", brier_score)\n","    \n","    # Return the model predictions, and the\n","    # test set\n","    # -------------------------------------\n","    out = {'model':best_model, 'y_pred_labels':y_pred}\n","    \n","    if probs_predicted:\n","        out.update({'y_pred_probs':y_pred_probs})\n","    else:\n","        y_pred_score = best_model.decision_function(X_test)\n","        out.update({'y_pred_score':y_pred_score})\n","        \n","    # Output results to file\n","    # ----------------------\n","    if probs_predicted and output_to_file:\n","        # Check whether any of the CV parameters are on the edge of\n","        # the search space\n","        opt_params_on_edge = find_opt_params_on_edge(cv_model)\n","        dump_to_output(model_name + \"::search_on_edge\", opt_params_on_edge)\n","        if print_to_screen:\n","            print(\"Were parameters on edge? : \" + str(opt_params_on_edge))\n","        \n","        # Find out how different the scores are for the different values\n","        # tested for by cross-validation. If they're not too different, then\n","        # even if the parameters are off the edge of the search grid, we should\n","        # be ok\n","        score_variation = find_score_variation(cv_model)\n","        dump_to_output(model_name + \"::score_variation\", score_variation)\n","        if print_to_screen:\n","            print(\"Score variations around CV search grid : \" + str(score_variation))\n","        \n","        # Print out all the scores\n","        dump_to_output(model_name + \"::all_cv_scores\", str(cv_model.cv_results_['mean_test_score']))\n","        if print_to_screen:\n","            print( str(cv_model.cv_results_['mean_test_score']) )\n","        \n","        # Dump the AUC to file\n","        dump_to_output(model_name + \"::roc_auc\", roc_auc_score(y_test, y_pred_probs) )\n","        \n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"aZg_an3ghSqE"},"source":["## 0.3 Models without grade or interest rate"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"Vkhg7rgDhSqF"},"source":["final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n","all_features = pd.Series(continuous_features + discrete_features_dummies)\n","idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in final_features]\n","\n","## useful when choosing the most significant features\n","selected_features = all_features[idx]\n","selected_features.reset_index(drop=True,inplace=True)\n","selected_features12 = selected_features.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rk0_z4ezhSqH"},"source":["## Process data here:\n","data_dict12 = prepare_data(data_subset = np.array([True]*len(data)), feature_subset = final_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"fChllwVZhSqJ"},"source":["### 0.3.1 Ridge Classifier"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"WY28fFxHhSqK"},"source":["cv_parameters = {\"alpha\":np.logspace(-4, 4, num = 10)}\n","# cv_parameters = {\"alpha\":[0.0001]}\n","ridge_clf07 = fit_classification(RidgeClassifier(), data_dict12, \n","                             cv_parameters = cv_parameters, model_name = \"Ridge Classifier\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvgkM7VCnoG_"},"source":["models_to_save['ridge_clf07'] = ridge_clf07"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"kp-ckxCshSqN"},"source":["### 0.3.2 Naive Bayes"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"pV13s6bhhSqN"},"source":["gnb07 = fit_classification(GaussianNB(), data_dict12,\n","                model_name = \"Gaussian Naive Bayes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMJNgwOensNc"},"source":["models_to_save['gnb07'] = gnb07"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"mH5Uff8thSqQ"},"source":["### 0.3.3 $l_1$ penalized logistic regression"]},{"cell_type":"code","metadata":{"id":"3nWh0piVan70"},"source":["l1_logistic07 = saved_models['l1_logistic07']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"NGBgwsrJhSqQ"},"source":["l1_logistic = LogisticRegression(penalty = 'l1',solver='liblinear')\n","cv_parameters = {\"C\":np.logspace(0, 6, num = 10)}\n","l1_logistic07 = fit_classification(l1_logistic, data_dict12,\n","                        cv_parameters = cv_parameters, model_name = \"l1 Penalized Logistic Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mvdEvnxgnyjp"},"source":["models_to_save['l1_logistic07'] = l1_logistic07"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lcqTd52BhSqT"},"source":["## plot top 3 features with the most positive (and negative) weights \n","top_and_bottom_idx = list(np.argsort(l1_logistic07['model'].coef_)[0,:3]) + list(np.argsort(l1_logistic07['model'].coef_)[0,-3:])\n","bplot = pd.Series(l1_logistic07['model'].coef_[0,top_and_bottom_idx])\n","xticks = selected_features[top_and_bottom_idx]\n","p1 = bplot.plot(kind='bar',rot=-30,ylim=(-5,5))\n","p1.set_xticklabels(xticks)\n","plt.title('Most significant features of l1_logisitic07')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"mTgGgqO4hSqV"},"source":["### 0.3.4 $l_2$ penalized logistic regression"]},{"cell_type":"code","metadata":{"id":"geLwJ5_xbpOR"},"source":["l2_logistic07 = saved_models['l2_logistic07']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true,"id":"Ejq1bVZQhSqV"},"source":["# l2_logistic07 = LogisticRegression(penalty = 'l2')\n","# cv_parameters = {\"C\":np.logspace(-4, 4, num = 10)}\n","\n","# l2_logistic07 = fit_classification(l2_logistic, data_dict12,\n","#                         cv_parameters = cv_parameters, model_name = \"l2 Penalized Logistic Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9l_1FC_fn4wi"},"source":["models_to_save['l2_logistic07'] = l2_logistic07"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"r_ZWVNC5hSqY"},"source":["## plot top 3 features with the most positive (and negative) weights \n","top_and_bottom_idx = list(np.argsort(l2_logistic07['model'].coef_)[0,:3]) + list(np.argsort(l2_logistic07['model'].coef_)[0,-3:])\n","bplot = pd.Series(l2_logistic07['model'].coef_[0,top_and_bottom_idx])\n","xticks = selected_features[top_and_bottom_idx]\n","p1 = bplot.plot(kind='bar',rot=-30,ylim=(-0.1,0.1))\n","p1.set_xticklabels(xticks)\n","plt.title('Most significant features of l2_logisitic07')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqOvGQo7hSqc"},"source":["coef_table = pd.DataFrame({\"feature\": selected_features[top_and_bottom_idx], \"coeff\": l2_logistic07['model'].coef_[0,top_and_bottom_idx]})\n","print(coef_table)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"YtsBMnuahSqf"},"source":["### 0.3.5 Decision tree"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"q_5kzw_OhSqf"},"source":["decision_tree = DecisionTreeClassifier()\n","cv_parameters = {'min_samples_leaf':[500,600,700,800,900,1000, 1100, 1200, 1300]}\n","\n","dt07 = fit_classification(decision_tree, data_dict12, \n","                          cv_parameters = cv_parameters, model_name = \"Decision tree\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3O2PJkZtn-qD"},"source":["models_to_save['dt07'] = dt07"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true,"id":"gRcSWB-GhSqh"},"source":["# Visualize the decision tree\n","# Zooming-in is allowed by double click\n","from sklearn.externals.six import StringIO \n","import graphviz\n","\n","dot_data = StringIO()\n","export_graphviz(dt07['model'], out_file=dot_data,  \n","                feature_names=selected_features,filled=True, rounded=True,\n","                special_characters=True)\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n","Image(graph.create_png())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TkYXSA-Jlzzq"},"source":["Note that due to the fact that the number of 5-year loans is significantly smaller than that of 3-year loans, the decision tree model made the first split based on the loan term. To offset that effect, the rules we considered for the strategy in the next step included only split decisions made at second nodes forward"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"Ym53QBnJhSqj"},"source":["### ($\\star$) 0.3.6 Random forest\n","Takes nearly 10 minutes given the large data set! So loading from saved output."]},{"cell_type":"code","metadata":{"id":"JJWjLoSwhSqj"},"source":["# Read models saved in a dictionary\n","rf07 = saved_models['rf07']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true,"id":"Ii1lK1wHhSql"},"source":["# random_forest = RandomForestClassifier()\n","# cv_parameters = {'min_samples_leaf':[1, 2, 3, 5, 8, 13, 17, 20, 40], 'n_estimators': [35, 60, 80, 100, 150] }\n","\n","# rf07 = fit_classification(random_forest, data_dict12,\n","#                                    cv_parameters=cv_parameters, model_name=\"Random forest\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CNPxMwEUQLS1"},"source":["#store the model\n","models_to_save['rf07'] = rf07"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"ADLXU-X0hSqn"},"source":["## Plot top 6 most significant features\n","top_idx = list(np.argsort(rf07['model'].feature_importances_)[-6:]) \n","bplot = pd.Series(rf07['model'].feature_importances_[top_idx])\n","xticks = selected_features[top_idx]\n","p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,0.2))\n","p2.set_xticklabels(xticks)\n","plt.title('Most significant features of rf07')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"LEcQl2aehSqq"},"source":["## A decision tree trained on the scores of random forest\n","trepin_tree = DecisionTreeClassifier(min_samples_leaf = 100, max_depth = 4)\n","trepin_tree.fit(rf07['y_pred_probs'].reshape(-1,1),data_dict12['y_test'])\n","dot_data = StringIO()\n","export_graphviz(trepin_tree, out_file=dot_data,  \n","                filled=True, rounded=True,\n","                special_characters=True)\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n","Image(graph.create_png())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"ZcQyCJVnhSqt"},"source":["### ($\\star$) 0.3.7 Bagged trees\n","Takes a very long time for the whole LC data set! So loading from saved output"]},{"cell_type":"code","metadata":{"id":"DRhQcN-LhSqt"},"source":["# Read models aved in a dictionary\n","bt07 = saved_models['bt07']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"39RKAcDohSqv"},"source":["# start = time.time()\n","# bt07 = RandomForestClassifier(max_features = 1.0)\n","# #cv_parameters = {'min_samples_leaf':[5, 10, 25, 50, 75, 100, 200], 'n_estimators': [60, 100, 150, 200, 300]}\n","# cv_parameters = {'min_samples_leaf':[50], 'n_estimators': [150]}\n","\n","\n","# bt07 = fit_classification(bt07, data_dict12,\n","#                                     cv_parameters=cv_parameters, model_name=\"Bagged trees\")\n","# print(\"time elapsed\",time.time()-start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzNYfTckZRGp"},"source":["models_to_save['bt07'] = bt07"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"1WxVycyjhSqx"},"source":["### 0.3.8 Multi-layer perceptron"]},{"cell_type":"code","metadata":{"id":"vLJIT04ehSqy"},"source":["# Read model saved in a dictionary\n","mlp07 = saved_models['mlp07']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"agMA_rR6hSq0"},"source":["# mlp07 = MLPClassifier()\n","# cv_parameters = {'hidden_layer_sizes':[(1), (10), (50), (100), (5, 5), (10, 10)]}\n","\n","# mlp07 = fit_classification(mlp07, data_dict12,\n","#                          cv_parameters = cv_parameters, model_name=\"Multi-Layer Perceptron\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kl02M0Irb2bc"},"source":["models_to_save['mlp07'] = mlp07"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VhADphVvhSq2"},"source":["# Step 1 - Time stability test of classifiers"]},{"cell_type":"markdown","metadata":{"id":"eIUj25ZKhSq2"},"source":["### 1.1 On the time period 2015-2016\n","\n","These models were already computed above on this data set. We will proceed to re-do them on data from a later time period."]},{"cell_type":"markdown","metadata":{"id":"AJVUHfkThSq2"},"source":["### 1.1.2 Load 2015-2016 data"]},{"cell_type":"code","metadata":{"id":"FMaKSPa7hSq3"},"source":["data15, discrete_features, continuous_features, ret_cols = pickle.load( open( pickle_input_201516, \"rb\" ) )\n","\n","#data = data13.copy()\n","data = downsample(data15, delProp = 0.70)\n","\n","### Mimic what we did for the 2012-2013 data\n","\n","# Create a feature for the length of a person's credit history at the\n","# time the loan is issued\n","data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n","data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n","continuous_features.append('cr_hist')\n","data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])\n","\n","\n","# Create a matrix of features and outcomes, with dummies. Record the\n","# names of the dummies for later use\n","X_continuous = data[continuous_features].values\n","\n","X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n","discrete_features_dummies = X_discrete.columns.tolist()\n","X_discrete = X_discrete.values\n","\n","X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n","\n","y = data.outcome.values\n","\n","train = data.train.values\n","\n","final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n","\n","\n","#data_dict = prepare_data(feature_subset = final_features)\n","all_features = pd.Series(continuous_features + discrete_features_dummies)\n","idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in final_features]\n","selected_features = all_features[idx]\n","selected_features.reset_index(drop=True,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_R4r3h6hSq6"},"source":["# prepare data \n","start_date_train = datetime.date(2015,1,1)\n","end_date_train = datetime.date(2015,9,1)\n","start_date_test = datetime.date(2015,10,1)\n","end_date_test = datetime.date(2015,12,1)\n","\n","data_dict15 = prepare_data(data_subset = np.array([True]*np.array([True]*len(data))),\n","                              date_range_train = (start_date_train, end_date_train),\n","                         date_range_test = (start_date_test, end_date_test),\n","                         n_samples_train = 20000, n_samples_test = 10000, feature_subset = final_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbMyzVE7hSq8"},"source":["## 1.2 Train on Q1-Q3 of 2015 and test on Q4 of 2015.\n","There are two intentions in looking for time stability.\n","- How do model performance based on 2012-13 data differ from those in a later time period, say trained from the first three quarters of 2015 and tested on the last quarter of 2015?\n","- The second intent is whether the top features of the same model (RF etc.) for 2012-13 were the same as those for 2015. \n","\n","We will see that the models trained across different time periods perform remarkably similar in terms of accuracy and other batch metrics, as well as \n","having similar top features. \n","\n","### 1.2.1 Ridge Classifier"]},{"cell_type":"code","metadata":{"id":"GZ1Z3cSbhSq9"},"source":["cv_parameters = {\"alpha\":np.logspace(-4, 4, num = 10)}\n","\n","ridge_clf13 = fit_classification(RidgeClassifier(), data_dict15,\n","                   cv_parameters = cv_parameters, model_name = \"Ridge Classfier\", output_to_file = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTy9L09xhSq_"},"source":["coef_table = pd.DataFrame({\"feature\": selected_features[top_and_bottom_idx], \"coeff\": ridge_clf13['model'].coef_[0,top_and_bottom_idx]})\n","print(coef_table)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH5g-ouVhSrB"},"source":["## Plot top 6 most significant features\n","temp = abs(ridge_clf13['model'].coef_[0])\n","top_idx = list(np.argsort(temp)[-6:]) # pick the highest 6 coef_ \n","bplot = pd.Series(temp[top_idx])\n","xticks = selected_features[top_idx]\n","p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,10))\n","p2.set_xticklabels(xticks)\n","plt.title('Most significant features of ridge_clf13')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xK6X3NpFhSrD"},"source":["## Plot top 6 most significant features\n","temp = abs(ridge_clf07['model'].coef_[0])\n","top_idx = list(np.argsort(temp)[-6:]) # pick the highest 6 coef_ \n","bplot = pd.Series(temp[top_idx])\n","xticks = selected_features[top_idx]\n","p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,1))\n","p2.set_xticklabels(xticks)\n","plt.title('Most significant features of ridge_clf07')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eAgXj2AqhSrF"},"source":["### 1.2.2 Naive Bayes: time-based train-test split"]},{"cell_type":"code","metadata":{"id":"Y_l6ZDZNhSrF"},"source":["gnb13 = fit_classification(GaussianNB(), data_dict15,\n","                model_name = \"Gaussian Naive Bayes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_i53f8DoPSY"},"source":["models_to_save['gnb13'] = gnb13"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eR3joqEdhSrH"},"source":["### 1.2.3 L1-regression"]},{"cell_type":"code","metadata":{"id":"P1rvTHuYhSrI"},"source":["l1 = LogisticRegression(penalty = 'l1',solver='liblinear')\n","cv_parameters = {\"C\":np.logspace(0, 6, num = 10)}\n","l1_logistic13 = fit_classification(l1, data_dict15,\n","                model_name = \"l1 Penalized Logistic Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OpVgX16oYEX"},"source":["models_to_save['l1_logistic13'] = l1_logistic13"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xoarih3VhSrK"},"source":["## plot top 3 features with the most positive (and negative) weights \n","top_and_bottom_idx = list(np.argsort(l1_logistic13['model'].coef_)[0,:3]) + list(np.argsort(l1_logistic13['model'].coef_)[0,-3:])\n","bplot = pd.Series(l1_logistic13['model'].coef_[0,top_and_bottom_idx])\n","xticks = selected_features[top_and_bottom_idx]\n","p1 = bplot.plot(kind='bar',rot=-30,ylim=(-5,5))\n","p1.set_xticklabels(xticks)\n","plt.title('Most significant features of l1_logistic13')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhgxPBG7hSrM"},"source":["## for comparison, plot top 3 features with the most positive (and negative) weights for 2007 data\n","top_and_bottom_idx = list(np.argsort(l1_logistic07['model'].coef_)[0,:3]) + list(np.argsort(l1_logistic07['model'].coef_)[0,-3:])\n","bplot = pd.Series(l1_logistic07['model'].coef_[0,top_and_bottom_idx])\n","xticks = selected_features[top_and_bottom_idx]\n","p1 = bplot.plot(kind='bar',rot=-30,ylim=(-5,5))\n","p1.set_xticklabels(xticks)\n","plt.title('Most significant features of l1_logisitic07')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXwpogzmhSrO"},"source":["### 1.2.4 L2-regression: time-based train-test split"]},{"cell_type":"code","metadata":{"id":"CxFdVy5ZhSrP"},"source":["l2 = LogisticRegression(penalty = 'l2')\n","cv_parameters = {\"C\":np.logspace(-4, 4, num = 10)}\n","l2_logistic13 = fit_classification(l2, data_dict15,\n","                model_name = \"l2 Penalized Logistic Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tv3Ui2yvoksO"},"source":["models_to_save['l2_logistic13'] = l2_logistic13"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bZRMIC7hSrS"},"source":["## plot top 3 features with the most positive (and negative) weights \n","top_and_bottom_idx = list(np.argsort(l2_logistic13['model'].coef_)[0,:3]) + list(np.argsort(l2_logistic13['model'].coef_)[0,-3:])\n","bplot = pd.Series(l2_logistic13['model'].coef_[0,top_and_bottom_idx])\n","xticks = selected_features[top_and_bottom_idx]\n","p1 = bplot.plot(kind='bar',rot=-30,ylim=(-2,2))\n","p1.set_xticklabels(xticks)\n","plt.title('Most significant features of l2_logistic on 2015 data')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdDn6FqOhSrU"},"source":["## for comparison, plot top 3 features with the most positive (and negative) weights for 2012\n","top_and_bottom_idx = list(np.argsort(l2_logistic07['model'].coef_)[0,:3]) + list(np.argsort(l2_logistic07['model'].coef_)[0,-3:])\n","bplot = pd.Series(l2_logistic07['model'].coef_[0,top_and_bottom_idx])\n","xticks = selected_features[top_and_bottom_idx]\n","p1 = bplot.plot(kind='bar',rot=-30,ylim=(-2,2))\n","p1.set_xticklabels(xticks)\n","plt.title('Most significant features of l2_logisitic on 2012-13')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxUr7iL_hSrX"},"source":["### 1.2.5 Decision tree: time-based train-test split"]},{"cell_type":"code","metadata":{"id":"khAB8yfehSrX"},"source":["cv_parameters = {'min_samples_leaf':[500,600,700,800,900,1000, 1100, 1200, 1300]}\n","dt13 = fit_classification(decision_tree, data_dict15, \n","                          cv_parameters = cv_parameters, model_name = \"Decision tree\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQaN0T8zoo7_"},"source":["models_to_save['dt13'] = dt13"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTd2qH16hSrZ"},"source":["# Visualize the decision tree\n","# Zooming-in is allowed by double click\n","from sklearn.externals.six import StringIO \n","import graphviz\n","\n","dot_data = StringIO()\n","export_graphviz(dt13['model'], \n","                out_file=dot_data,  \n","                feature_names=selected_features,filled=True, \n","                rounded=True,\n","                special_characters=True)\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n","Image(graph.create_png())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bADmWgHqhSre"},"source":["# For comparison from 2012\n","from sklearn.externals.six import StringIO \n","import graphviz\n","\n","dot_data = StringIO()\n","export_graphviz(dt07['model'], out_file=dot_data,  \n","                feature_names=selected_features12,filled=True, rounded=True,\n","                special_characters=True)\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n","Image(graph.create_png())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTy5NG2WmQ6e"},"source":["FICO range high or low, annual income and dti appears on top splits in both models running on 12 and 15."]},{"cell_type":"markdown","metadata":{"id":"uQaVXRuwhSrg"},"source":["### ($\\star$) 1.2.6 Random Forest.\n","Takes 10 minutes, so loading from memory"]},{"cell_type":"code","metadata":{"id":"7o0n7zGrhSrh"},"source":["# Load Saved Model  \n","rf13 = saved_models['rf13']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6a5-6jqIhSrj"},"source":["# # Commands used to generate rf13:\n","# cv_parameters = {'min_samples_leaf':[1, 2, 3, 5, 8, 13, 17, 20, 40], 'n_estimators': [35, 60, 80, 100, 150] }\n","\n","# rf13 = fit_classification(RandomForestClassifier(), data_dict15,\n","#                                    cv_parameters=cv_parameters, model_name=\"Random forest\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpoZKmuXd5bM"},"source":["models_to_save['rf13'] = rf13"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nCrtrMtX95HS"},"source":["###  1.2.7 Multi Layer Perceptron"]},{"cell_type":"code","metadata":{"id":"ox_rQh2C-J4t"},"source":["# Read model saved in a dictionary\n","mlp13 = saved_models['mlp13']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"vG42Z8SR-J4x"},"source":["# mlp13 = MLPClassifier()\n","# cv_parameters = {'hidden_layer_sizes':[(1), (10), (50), (100), (5, 5), (10, 10)]}\n","\n","# mlp13 = fit_classification(mlp13, data_dict15,\n","#                          cv_parameters = cv_parameters, model_name=\"Multi-Layer Perceptron\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-DR9P7m-d8H"},"source":["models_to_save['mlp13'] = mlp13"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDHSBioqo0cP"},"source":["models_to_save.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YoK8A77BhSrm"},"source":["### Comparison: Random forest run - 2012-13 vs 2015\n","We see that the 3 of the top 6 features are the same."]},{"cell_type":"code","metadata":{"id":"pUR72fRmhSrm"},"source":["## Plot top 6 most significant features\n","top_idx = list(np.argsort(rf07['model'].feature_importances_)[-6:]) \n","bplot = pd.Series(rf07['model'].feature_importances_[top_idx])\n","xticks = selected_features[top_idx]\n","p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,0.2))\n","p2.set_xticklabels(xticks)\n","plt.title('Most significant features of RF run on 2012-13')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYO1Cbl4hSro"},"source":["## Plot top 6 most significant features\n","top_idx = list(np.argsort(rf13['model'].feature_importances_)[-6:]) \n","bplot = pd.Series(rf13['model'].feature_importances_[top_idx])\n","xticks = selected_features[top_idx]\n","p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,0.2))\n","p2.set_xticklabels(xticks)\n","plt.title('Most significant features of RF run on 2015')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0kOUAOzhSrr"},"source":["# 2. Build and Test Regression Models for returns"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"pWeVqddxhSrr"},"source":["def fit_regression(model, data_dict,\n","                      cv_parameters = {},\n","                      separate = False,\n","                      model_name = None,\n","                      random_state = default_seed,\n","                      output_to_file = True,\n","                      print_to_screen = True):\n","    '''\n","    This function will fit a regression model to data and print various evaluation\n","    measures. It expects the following parameters\n","      - model: an sklearn model object\n","      - data_dict: the dictionary containing both training and testing data;\n","                   returned by the prepare_data function\n","      - separate: a Boolean variable indicating whether we fit models for\n","                  defaulted and non-defaulted loans separately\n","      - cv_parameters: a dictionary of parameters that should be optimized\n","                       over using cross-validation. Specifically, each named\n","                       entry in the dictionary should correspond to a parameter,\n","                       and each element should be a list containing the values\n","                       to optimize over\n","      - model_name: the name of the model being fit, for printouts\n","      - random_state: the random seed to use\n","      - output_to_file: if the results will be saved to the output file\n","      - print_to_screen: if the results will be printed on screen\n","\n","    This function returns a dictionary FOR EACH RETURN DEFINITION with the following entries\n","      - model: the best fitted model\n","      - predicted_return: prediction result based on the test set\n","      - predicted_regular_return: prediction result for non-defaulted loans (valid if separate == True)\n","      - predicted_default_return: prediction result for defaulted loans (valid if separate == True)\n","      - r2_scores: the testing r2_score(s) for the best fitted model\n","    '''\n","\n","    np.random.seed(random_state)\n","\n","    # --------------------------\n","    #   Step 1 - Load the data\n","    # --------------------------\n","\n","    col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb', 'ret_INTc', 'ret_Hybrid']\n","\n","    X_train = data_dict['X_train']\n","    filter_train = data_dict['train_set']\n","\n","    X_test = data_dict['X_test']\n","    filter_test = data_dict['test_set']\n","    out = {}\n","\n","    for ret_col in col_list:\n","\n","        #y_train = data.loc[filter_train, ret_col].as_matrix()\n","        #y_test = data.loc[filter_test, ret_col].as_matrix()\n","        y_train = data.loc[filter_train, ret_col].to_numpy()\n","        y_test = data.loc[filter_test, ret_col].to_numpy()\n","\n","        # --------------------------\n","        #   Step 2 - Fit the model\n","        # --------------------------\n","\n","        if separate:\n","            outcome_train = data.loc[filter_train, 'outcome']\n","            outcome_test = data.loc[filter_test, 'outcome']\n","\n","            # Train two separate regressors for defaulted and non-defaulted loans\n","            X_train_0 = X_train[outcome_train == False]\n","            y_train_0 = y_train[outcome_train == False]\n","            X_test_0 = X_test[outcome_test == False]\n","            y_test_0 = y_test[outcome_test == False]\n","\n","            X_train_1 = X_train[outcome_train == True]\n","            y_train_1 = y_train[outcome_train == True]\n","            X_test_1 = X_test[outcome_test == True]\n","            y_test_1 = y_test[outcome_test == True]\n","\n","            cv_model_0 = GridSearchCV(model, cv_parameters, scoring='r2')\n","            cv_model_1 = GridSearchCV(model, cv_parameters, scoring='r2')\n","\n","            start_time = time.time()\n","            cv_model_0.fit(X_train_0, y_train_0)\n","            cv_model_1.fit(X_train_1, y_train_1)\n","            end_time = time.time()\n","\n","            best_model_0 = cv_model_0.best_estimator_\n","            best_model_1 = cv_model_1.best_estimator_\n","\n","            if print_to_screen:\n","\n","                if model_name != None:\n","                    print(\"=========================================================\")\n","                    print(\"  Model: \" + model_name + \"  Return column: \" + ret_col)\n","                    print(\"=========================================================\")\n","\n","                print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n","                print(\"Optimal parameters:\")\n","                print(\"model_0:\",cv_model_0.best_params_, \"model_1\",cv_model_1.best_params_)\n","\n","            predicted_regular_return = best_model_0.predict(X_test)\n","            predicted_default_return = best_model_1.predict(X_test)\n","\n","            if print_to_screen:\n","                print(\"\")\n","                print(\"Testing r2 scores:\", )\n","            # Here we use different testing set to report the performance\n","            test_scores = {'model_0':r2_score(y_test_0,best_model_0.predict(X_test_0)),\n","                              'model_1':r2_score(y_test_1,best_model_1.predict(X_test_1))}\n","            if print_to_screen:\n","                print(\"model_0 (non-default):\", test_scores['model_0'])\n","                print(\"model_1 (default):\", test_scores['model_1'])\n","                print('Avg Predicted regular return:', np.sum(predicted_regular_return)/len(predicted_regular_return))\n","                print('Avg Predicted default return:', np.sum(predicted_default_return)/len(predicted_default_return))\n","\n","            cv_objects = {'model_0':cv_model_0, 'model_1':cv_model_1}\n","            out[ret_col] = { 'model_0':best_model_0, 'model_1':best_model_1, 'predicted_regular_return':predicted_regular_return,\n","                      'predicted_default_return':predicted_default_return,'r2_scores':test_scores }\n","\n","        else:\n","            cv_model = GridSearchCV(model, cv_parameters, scoring='r2')\n","\n","            start_time = time.time()\n","            cv_model.fit(X_train, y_train)\n","            end_time = time.time()\n","\n","            best_model = cv_model.best_estimator_\n","\n","            if print_to_screen:\n","                if model_name != None:\n","                    print(\"=========================================================\")\n","                    print(\"  Model: \" + model_name + \"  Return column: \" + ret_col)\n","                    print(\"=========================================================\")\n","\n","                print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n","                print(\"Optimal parameters:\")\n","                print(cv_model.best_params_)\n","\n","            predicted_return = best_model.predict(X_test)\n","            test_scores = {'model':r2_score(y_test,predicted_return)}\n","            if print_to_screen:\n","                print(\"\")\n","                print(\"Testing r2 score:\", test_scores['model'])\n","                print(\"Avg Predcited return:\", np.sum(predicted_return)/len(predicted_return))\n","\n","            cv_objects = {'model':cv_model}\n","            out[ret_col] = {'model':best_model, 'predicted_return':predicted_return, 'r2_scores':r2_score(y_test,predicted_return)}\n","\n","        # Output the results to a file\n","        if output_to_file:\n","            for i in cv_objects:\n","                # Check whether any of the CV parameters are on the edge of\n","                # the search space\n","                opt_params_on_edge = find_opt_params_on_edge(cv_objects[i])\n","                dump_to_output(model_name + \"::\" + ret_col + \"::search_on_edge\", opt_params_on_edge)\n","                if print_to_screen:\n","                    print(\"Were parameters on edge (\" + i + \") : \" + str(opt_params_on_edge))\n","\n","                # Find out how different the scores are for the different values\n","                # tested for by cross-validation. If they're not too different, then\n","                # even if the parameters are off the edge of the search grid, we should\n","                # be ok\n","                score_variation = find_score_variation(cv_objects[i])\n","                dump_to_output(model_name + \"::\" + ret_col + \"::score_variation\", score_variation)\n","                if print_to_screen:\n","                    print(\"Score variations around CV search grid (\" + i + \") : \" + str(score_variation))\n","\n","                # Print out all the scores\n","                dump_to_output(model_name + \"::all_cv_scores\", str(cv_objects[i].cv_results_['mean_test_score']))\n","                if print_to_screen:\n","                    print(\"All test scores : \" + str(cv_objects[i].cv_results_['mean_test_score']) )\n","\n","                # Dump the AUC to file\n","                dump_to_output( model_name + \"::\" + ret_col + \"::r2\", test_scores[i] )\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%%\n"},"id":"tchYPubDhSru"},"source":["## 2.1 Test regression models on 2012-2013 data\n","Unlike prevous week on classification models, we decided to apply regressors on full dataset. "]},{"cell_type":"markdown","metadata":{"id":"d6gK-LJFv2JG"},"source":["## For All Returns"]},{"cell_type":"code","metadata":{"id":"m1yHKF6QRV3E"},"source":["# Read the data and features from the pickle\n","data12, discrete_features, continuous_features, ret_cols = pickle.load( open( pickle_input_201213, \"rb\" ) )\n","\n","#data = data12.copy()\n","data = downsample(data12, delProp = 0.75)\n","\n","# Create the outcome\n","data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n","\n","# Create a feature for the length of a person's credit history at the\n","# time the loan is issued\n","data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n","continuous_features.append('cr_hist')\n","\n","\n","# Randomly assign each row to a training and test set. We do this now\n","# because we will be fitting a variety of models on various time periods,\n","# and we would like every period to use the *same* training/test split\n","np.random.seed(default_seed)\n","data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])\n","\n","# Create a matrix of features and outcomes, with dummies. Record the\n","# names of the dummies for later use\n","X_continuous = data[continuous_features].values\n","\n","X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n","discrete_features_dummies = X_discrete.columns.tolist()\n","X_discrete = X_discrete.values\n","\n","X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n","\n","y = data.outcome.values\n","\n","train = data.train.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EP41w58zRwBL"},"source":["final_features = [i for i in discrete_features + continuous_features if i not in [\"installment\"]]\n","all_features = pd.Series(continuous_features + discrete_features_dummies)\n","idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in final_features]\n","\n","## useful when choosing the most significant features\n","selected_features = all_features[idx]\n","selected_features.reset_index(drop=True,inplace=True)\n","selected_features12 = selected_features.copy()\n","\n","## Process data here:\n","data_dict12 = prepare_data(data_subset = np.array([True]*len(data)), feature_subset = final_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ls0jM_YrhSrz"},"source":["### 2.1.1 Lasso-Lars regressor"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"GatLnkgChSr0"},"source":["# First, trying LASSO penalized regression with a variety of parameters,\n","# it becomes clear a simple regression is best\n","\n","cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_lasso07 = fit_regression(linear_model.LassoLars(), data_dict12, \n","               cv_parameters = cv_parameters, separate = False, model_name = \"Lasso\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XbXnVAXhSr2"},"source":["### 2.1.2 Ridge regressor"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"w35buoW1hSr3"},"source":["cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_ridge07 = fit_regression(linear_model.Ridge(), data_dict12,\n","               cv_parameters = cv_parameters, separate = False, model_name = \"Ridge\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uezNWI1BhSr5"},"source":["### 2.1.3 Ordinary least squares"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"_t1t5lRthSr5"},"source":["reg_linear12 = fit_regression(linear_model.LinearRegression(), data_dict12,\n","               separate = False, model_name = \"Linear Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJ4Rp_SuhSr7"},"source":["### ($\\star$) 2.1.4 Multi-layer perceptron regressor"]},{"cell_type":"code","metadata":{"id":"Gh61TKkfyheP"},"source":["# you may skip the computation by running:\n","reg_mlp12 = saved_models['reg_mlp12'] \n","reg_mlp12"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqtowF3U4gIB"},"source":["# cv_parameters = { 'alpha':[0.001, 0.01, 0.1, 1, 10, 100],\n","#                   'hidden_layer_sizes':[(1), (10), (50), (100), (200), (5, 5), (10, 10)] }\n","\n","# reg_mlp12 = fit_regression(MLPRegressor(), data_dict12,\n","#                cv_parameters = cv_parameters, separate = False, model_name = \"Multi-Layer Perceptron\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xNGAwQXhSr-"},"source":["### ($\\star$) 2.1.5 Random forest regressor"]},{"cell_type":"code","metadata":{"id":"350EbIHVhSr_"},"source":["# you may skip the computation by running:\n","reg_rf12 = saved_models['reg_rf12'] \n","reg_rf12"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"LjAbmrJ_hSsB"},"source":["# cv_parameters = {'min_samples_leaf':[75, 100, 200, 300, 400],\n","#                  'n_estimators': [35, 45, 55, 65, 80, 90, 100] }\n","\n","# reg_rf07 = fit_regression(RandomForestRegressor(), data_dict07,\n","#                cv_parameters = cv_parameters, separate = False, model_name = \"Random forest regressor\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwS9yPoFzddt"},"source":["## For Defaulted Loans & Nondefaulted Loans\n"]},{"cell_type":"markdown","metadata":{"id":"VG_FY6iozkHH"},"source":["### 2.1.1 Lasso-Lars regressor"]},{"cell_type":"code","metadata":{"id":"8qtgk58AzjbE"},"source":["# First, trying LASSO penalized regression with a variety of parameters,\n","# it becomes clear a simple regression is best\n","\n","cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_lasso07 = fit_regression(linear_model.LassoLars(), data_dict12, \n","               cv_parameters = cv_parameters, separate = True, model_name = \"Lasso\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oWfiCJOhzrTj"},"source":["### 2.1.2 Ridge regressor"]},{"cell_type":"code","metadata":{"id":"_CREpDPCzuBe"},"source":["cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_ridge07 = fit_regression(linear_model.Ridge(), data_dict12,\n","               cv_parameters = cv_parameters, separate = True, model_name = \"Ridge\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OXQGobhKzwMn"},"source":["### 2.1.3 Ordinary least squares"]},{"cell_type":"code","metadata":{"id":"yLdg2iY0zydU"},"source":["reg_linear07 = fit_regression(linear_model.LinearRegression(), data_dict12,\n","               separate = True, model_name = \"Linear Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zL0lodCz0zL"},"source":["### ($\\star$) 2.1.4 Multi-layer perceptron regressor"]},{"cell_type":"code","metadata":{"id":"hwUZe6kRz1Tx"},"source":["# you may skip the computation by running:\n","reg_mlp12_df = saved_models['reg_mlp12_df'] \n","reg_mlp12_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfYB9zcez8wR"},"source":["# cv_parameters = { 'alpha':[0.001, 0.01, 0.1, 1, 10, 100],\n","#                   'hidden_layer_sizes':[(1), (10), (50), (100), (200), (5, 5), (10, 10)] }\n","\n","# reg_mlp12 = fit_regression(MLPRegressor(), data_dict12,\n","#                cv_parameters = cv_parameters, separate = True, model_name = \"Multi-Layer Perceptron\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8kF5ZD9I0NMX"},"source":["### ($\\star$) 2.1.5 Random forest regressor"]},{"cell_type":"code","metadata":{"id":"h4Od2mPB0OLv"},"source":["# you may skip the computation by running:\n","reg_rf12_df = saved_models['reg_rf12_df']\n","reg_rf12_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHZzCJyx0Tbn"},"source":["# cv_parameters = {'min_samples_leaf':[75, 100, 200, 300, 400],\n","#                  'n_estimators': [35, 45, 55, 65, 80, 90, 100] }\n","\n","# reg_rf12 = fit_regression(RandomForestRegressor(), data_dict07,\n","#                cv_parameters = cv_parameters, separate = True, model_name = \"Random forest regressor\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5Ejlh2BhSsD"},"source":["## 2.2 Test on 2015-2016 data\n","\n","Testing same regressors on dataset in different periods to test out the time stability. The result shows that 2012-2013 has a slightly better r2 scores than 2015-2016"]},{"cell_type":"markdown","metadata":{"id":"6RMPrkdt0gjU"},"source":["## For All Returns"]},{"cell_type":"code","metadata":{"id":"9IjOez9BSzNh"},"source":["data15, discrete_features, continuous_features, ret_cols = pickle.load( open( pickle_input_201516, \"rb\" ) )\n","\n","#data = data13.copy()\n","data = downsample(data15, delProp = 0.70)\n","\n","### Mimic what we did for the 2012-2013 data\n","\n","# Create a feature for the length of a person's credit history at the\n","# time the loan is issued\n","data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n","data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n","continuous_features.append('cr_hist')\n","data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])\n","\n","\n","# Create a matrix of features and outcomes, with dummies. Record the\n","# names of the dummies for later use\n","X_continuous = data[continuous_features].values\n","\n","X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n","discrete_features_dummies = X_discrete.columns.tolist()\n","X_discrete = X_discrete.values\n","\n","X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n","\n","y = data.outcome.values\n","\n","train = data.train.values\n","\n","final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n","\n","\n","#data_dict = prepare_data(feature_subset = final_features)\n","all_features = pd.Series(continuous_features + discrete_features_dummies)\n","idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in final_features]\n","selected_features = all_features[idx]\n","selected_features.reset_index(drop=True,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxuSvJ46S3B7"},"source":["# prepare data \n","start_date_train = datetime.date(2015,1,1)\n","end_date_train = datetime.date(2015,9,1)\n","start_date_test = datetime.date(2015,10,1)\n","end_date_test = datetime.date(2015,12,1)\n","\n","data_dict15 = prepare_data(data_subset = np.array([True]*np.array([True]*len(data))),\n","                              date_range_train = (start_date_train, end_date_train),\n","                         date_range_test = (start_date_test, end_date_test),\n","                         n_samples_train = 20000, n_samples_test = 10000, feature_subset = final_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zEvAPU-phSsG"},"source":["### 2.2.1 Lasso-LARS regressor "]},{"cell_type":"code","metadata":{"id":"9WXN0i2NhSsG"},"source":["# First, trying LASSO penalized regression with a variety of parameters,\n","# it becomes clear a simple regression is best\n","\n","cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_lasso13 = fit_regression(linear_model.LassoLars(), data_dict15,\n","               cv_parameters = cv_parameters, separate = False, model_name = \"Lasso\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y8sTd7JxhSsJ"},"source":["### 2.2.2 Ridge regressor"]},{"cell_type":"code","metadata":{"id":"u2hZA2DGhSsJ"},"source":["cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_ridge13 = fit_regression(linear_model.Ridge(), data_dict15,\n","               cv_parameters = cv_parameters, separate = False, model_name = \"Ridge\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xisnINQGhSsK"},"source":["### 2.2.3 Ordinary Least Squares"]},{"cell_type":"code","metadata":{"id":"w_5r81V5hSsL"},"source":["reg_linear13 = fit_regression(linear_model.LinearRegression(), data_dict15,\n","               separate = False, model_name = \"Linear Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vk3_CAIGhSsM"},"source":["###  2.2.4 ($\\star$) Multi-layer perceptron regressor"]},{"cell_type":"code","metadata":{"id":"guflxFB7hSsM"},"source":["# you may skip the computation by running:\n","reg_mlp15 = saved_models['reg_mlp15']\n","reg_mlp15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8QS5eAQhSsO"},"source":["# cv_parameters = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100],\n","#                   'hidden_layer_sizes':[(1), (10), (50), (100), (200), (5, 5), (10, 10)] }\n","\n","# reg_mlp15 = fit_regression(MLPRegressor(), data_dict15,\n","#                cv_parameters = cv_parameters, separate = False, model_name = \"Multi-Layer Perceptron\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOkjSfSShSsQ"},"source":["###  2.2.5 ($\\star$) Random forest regressor"]},{"cell_type":"code","metadata":{"id":"6b1U7dCXhSsQ"},"source":["# you may skip the computation by running:\n","reg_rf15 = saved_models['reg_rf15'] \n","reg_rf15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HO0szDr8hSsT"},"source":["# cv_parameters = {'min_samples_leaf':[75, 100, 200, 300, 400],\n","#                  'n_estimators': [35, 45, 55, 65, 80, 90, 100] }\n","\n","# reg_rf15 = fit_regression(RandomForestRegressor(), data_dict15,\n","#                cv_parameters = cv_parameters, separate = False, model_name = \"Random forest regressor\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"abuUgsBt05g5"},"source":["## For Defaulted Loans & Nondefaulted Loans\n"]},{"cell_type":"markdown","metadata":{"id":"1A_qea3308WD"},"source":["### 2.2.1 Lasso-LARS regressor "]},{"cell_type":"code","metadata":{"id":"wUcAOd2w0_MH"},"source":["# First, trying LASSO penalized regression with a variety of parameters,\n","# it becomes clear a simple regression is best\n","\n","cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_lasso13 = fit_regression(linear_model.LassoLars(), data_dict15,\n","               cv_parameters = cv_parameters, separate = True, model_name = \"Lasso\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wh3Pnqi91NXp"},"source":["### 2.1.2 Ridge regressor"]},{"cell_type":"code","metadata":{"id":"gTGVqkos1N8H"},"source":["cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n","\n","reg_ridge13 = fit_regression(linear_model.Ridge(), data_dict15,\n","               cv_parameters = cv_parameters, separate = True, model_name = \"Ridge\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SJRgtU0g1SV_"},"source":["### 2.2.3 Ordinary Least Squares"]},{"cell_type":"code","metadata":{"id":"LyACvaSu1S94"},"source":["reg_linear15 = fit_regression(linear_model.LinearRegression(), data_dict15,\n","               separate = True, model_name = \"Linear Regression\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Zp3vKGB1XWL"},"source":["###  2.2.4 ($\\star$) Multi-layer perceptron regressor"]},{"cell_type":"code","metadata":{"id":"usQp9Zud1YMy"},"source":["# you may skip the computation by running:\n","reg_mlp15_df = saved_models['reg_mlp15_df']\n","reg_mlp15_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0jhfr7l1VEN"},"source":["###  2.2.5 ($\\star$) Random forest regressor"]},{"cell_type":"code","metadata":{"id":"pTMr7AWr1g_s"},"source":["# you may skip the computation by running:\n","reg_rf15_df = saved_models['reg_rf15_df']\n","reg_rf15_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"tzXX86wShSsV"},"source":["# Step 3 - Test investment strategies\n","Now we test several investment strategies using the learning models above.\n","\n","*Note - we added our additional return columns to the below function, as well as the following strategies:*\n","\n","*   Best possible: For benchmarking purposes only. Return the average of the top n loans.\n","*   Tree-based: Pick top two rules from decision tree models built last week. Use those rules to determine top loans. This model is explained in more detail in this week's report.\n","\n"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"XGnUbe-lhSsW"},"source":["def test_investments(data_dict,\n","                        classifier = None,\n","                        regressor = None,\n","                        strategy = 'Random',\n","                        num_loans = 1000,\n","                        random_state = default_seed,\n","                        output_to_file = True):\n","    '''\n","    This function tests a variety of investment methodologies and their returns.\n","    It will run its tests on the loans defined by the test_set element of the data\n","    dictionary.\n","\n","    It is currently able to test four strategies\n","      - random: invest in a random set of loans\n","      - ranking: score each loan by probability of default, and only invest\n","                 in the \"safest\" loans (i.e., those with the lowest probabilities\n","                 of default)\n","      - regression: train a single regression model to predict the expected return\n","                    of loans in the past. Then, for loans we could invest in, simply\n","                    rank them by their expected returns and invest in that order.\n","      - two-stage: train two regression models to predict the expected return of\n","                   defaulted loans and non-defaulted loans in the training set. Then,\n","                   for each potential loan we could invest in, predict the probability\n","                   the loan will default, its return if it doesn't default and its\n","                   return if it does. Then, calculate a weighted combination of\n","                   the latter using the former to find a predicted return. Rank the\n","                   loans by this expected return, and invest in that order\n","      - tree-based: pick top (quantified by largest cut) 2 rules  out by decision trees\n","                    model output from last week run. Filter the test loans for those rules and \n","                    invest out of those filtered loans. Then, calculate the average return.\n","\n","    It expects the following parameters\n","      - data: the data set we are using now\n","      - data_dict: the dictionary containing both training and testing data;\n","                   returned by the prepare_data function\n","      - classifier: a fitted model object which is returned by the fit_classification function.\n","      - regressor: a fitted model object which is returned by the fit_regression function.\n","      - strategy: the name of the strategy; one of the three listed above\n","      - num_loans: the number of loans to be included in the test portfolio\n","      - num_samples: the number of random samples used to compute average return ()\n","      - random_state: the random seed to use when selecting a subset of rows\n","      - output_to_file: if the results will be saved to the output file\n","\n","    The function returns a dictionary FOR EACH RETURN DEFINITION with the following entries\n","      - strategy: the name of the strategy\n","      - average return: the return of the strategy based on the testing set\n","      - test data: the updated Dataframe of testing data. Useful in the optimization section\n","    '''\n","\n","    np.random.seed(random_state)\n","\n","    # Retrieve the rows that were used to train and test  the\n","    # classification model\n","    train_set = data_dict['train_set']\n","    test_set = data_dict['test_set']\n","\n","    col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb','ret_INTc','ret_Hybrid']\n","\n","    # Create a dataframe for testing, including the score\n","    data_test = data.loc[test_set,:]\n","    out = {}\n","\n","    for ret_col in col_list:\n","\n","        if strategy == 'Random':\n","            # Randomize the order of the rows in the datframe\n","            data_test = data_test.sample(frac = 1).reset_index(drop = True)\n","\n","            # Select num_loans to invest in\n","            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n","\n","            # Find the average return for these loans\n","            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n","\n","            # Return\n","            out[ret_col] = {'strategy':strategy, 'average return':ret_test}\n","\n","            # Dump the strategy performance to file\n","            if output_to_file:\n","                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n","\n","            continue\n","\n","        elif strategy == 'Regression':\n","\n","            colname = 'predicted_return_' + ret_col\n","\n","            data_test[colname] = regressor[ret_col]['predicted_return']\n","\n","            # Sort the loans by predicted return\n","            data_test = data_test.sort_values(by=colname, ascending = False).reset_index(drop = True)\n","\n","            # Pick num_loans loans\n","            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n","\n","            # Find their return\n","            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n","\n","            # Return\n","            out[ret_col] = {'strategy':strategy, 'average return':ret_test, 'test data':data_test}\n","\n","            # Dump the strategy performance to file\n","            if output_to_file:\n","                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n","\n","            continue\n","\n","        elif strategy == \"Best Possible\":\n"," \n","            # Sort the loans by ACTUAL return\n","            data_test = data_test.sort_values(by=ret_col, ascending = False).reset_index(drop = True)\n","            \n","            # Pick num_loans loans\n","            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n","\n","            # Find their return\n","            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n","\n","            # Return\n","            out[ret_col] = {'strategy':strategy, 'average return':ret_test, 'test data':data_test}\n","\n","            # Dump the strategy performance to file\n","            if output_to_file:\n","                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n","\n","            continue\n","\n","        # Get the predicted scores, if the strategy is not Random or just Regression\n","        try:\n","            y_pred_score = classifier['y_pred_probs']\n","        except:\n","            y_pred_score = classifier['y_pred_score']\n","\n","        data_test['score'] = y_pred_score\n","\n","        if strategy == 'Ranking':\n","            # Sort the test data by the score\n","            data_test = data_test.sort_values(by='score').reset_index(drop = True)\n","\n","            # Select num_loans to invest in\n","            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n","\n","            # Find the average return for these loans\n","            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n","\n","            # Return\n","            out[ret_col] = {'strategy':strategy, 'average return':ret_test}\n","\n","            # Dump the strategy performance to file\n","            if output_to_file:\n","                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n","\n","            continue\n","\n","\n","        elif strategy == 'Two-stage':\n","\n","            # Load the predicted returns\n","            data_test['predicted_regular_return'] = regressor[ret_col]['predicted_regular_return']\n","            data_test['predicted_default_return'] = regressor[ret_col]['predicted_default_return']\n","\n","            # Compute expectation\n","            colname = 'predicted_return_' + ret_col\n","\n","            data_test[colname] = ( (1-data_test.score)*data_test.predicted_regular_return +\n","                                             data_test.score*data_test.predicted_default_return )\n","\n","            # Sort the loans by predicted return\n","            data_test = data_test.sort_values(by=colname, ascending = False).reset_index(drop = True)\n","\n","            # Pick num_loans loans\n","            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n","\n","            # Find their return\n","            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n","\n","            # Return\n","            out[ret_col] = {'strategy':strategy, 'average return':ret_test, 'test data':data_test}\n","\n","            # Dump the strategy performance to file\n","            if output_to_file:\n","                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n","\n","            continue\n","\n","        elif strategy == 'Tree-based':\n","            # Define rules based on optimal tree nodes\n","            # FICO RANGE HIGH > 0.363 AND ANNUAL_INC > 0.448\n","            rule_1 = (data_test['fico_range_high'] > 0.363) & (data_test['annual_inc'] > 0.448) \n","            # OR: FICO_RANGE_HIGH < 0.228 AND DTI < 0.358\n","            rule_2 = (data_test['fico_range_high'] < 0.228) & (data_test['dti'] < 0.358) \n","            # Filter for loans to pick\n","            pf_test = data_test.loc[(rule_1) | (rule_2)]\n","            # Pick num_loans loans, if num_loans exceed available loans, return 'num_loans exceed loan availability'\n","            if num_loans <= len(pf_test):\n","              pf_test = pf_test.iloc[:num_loans]\n","              ret_test = np.mean(pf_test[ret_col])\n","            else:\n","              ret_test = 'num_loans exceed loan availability'\n","            # Returns\n","            out[ret_col] = {'strategy':strategy, 'average return':ret_test, 'test data':data_test}\n","            # Dump the strategy performance to file\n","            if output_to_file:\n","                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n","            continue\n","\n","\n","        else:\n","            return 'Not a valid strategy'\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"89IJ4_HAhSsY"},"source":["# Step 4 - Implement the test strategies on 2012-2013 data"]},{"cell_type":"markdown","metadata":{"id":"Pwv_IPdcyacC"},"source":["## 4.01 Re-load full 2012-13 dataset\n","\n","Load in the full 2012/13 dataset again for strategy testing. Recall the dataset was downsampled earlier for classifier model training. We will re-split into train/test sets with the true balance of default vs. non-default."]},{"cell_type":"code","metadata":{"id":"pO1EW3dJxAda"},"source":["data = data12.copy()\n","\n","# Create the outcome\n","data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n","\n","# Create a feature for the length of a person's credit history at the\n","# time the loan is issued\n","data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n","\n","# Randomly assign each row to a training and test set. We do this now\n","# because we will be fitting a variety of models on various time periods,\n","# and we would like every period to use the *same* training/test split\n","np.random.seed(default_seed)\n","data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])\n","\n","# Create a matrix of features and outcomes, with dummies. Record the\n","# names of the dummies for later use\n","X_continuous = data[continuous_features].values\n","\n","X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n","discrete_features_dummies = X_discrete.columns.tolist()\n","X_discrete = X_discrete.values\n","\n","X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n","\n","y = data.outcome.values\n","\n","train = data.train.values\n","\n","final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n","all_features = pd.Series(continuous_features + discrete_features_dummies)\n","idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in final_features]\n","\n","## useful when choosing the most significant features\n","selected_features = all_features[idx]\n","selected_features.reset_index(drop=True,inplace=True)\n","selected_features12 = selected_features.copy()\n","\n","## Process data here:\n","data_dict12_strat = prepare_data(data_subset = np.array([True]*len(data)), feature_subset = final_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ldW4W4J-4CI"},"source":["## 4.02 Predict probability of default and return on the test data\n","\n","Since we are using the full (not downsampled) dataset to test strategies, we need to run our trained models (read from the saved model file) on the full dataset to obtain predictions.\n","\n","We also need to transform the score predictions for the classifier model, due to the sample change from training to strategy testing."]},{"cell_type":"code","metadata":{"id":"TqUy6Bsp4uJp"},"source":["# Choose the default classifier\n","default_classifier = saved_models['l1_logistic07'].copy()\n","\n","# Choose the return regressor\n","return_regressor = saved_models['reg_rf12'].copy()\n","\n","# Choose the separate return regressor\n","return_regressor_separate = saved_models['reg_rf12_df'].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StACZYxQ0QBK","executionInfo":{"status":"ok","timestamp":1601347036420,"user_tz":240,"elapsed":606,"user":{"displayName":"Stefanie Montgomery","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1cx63USwKWPl5_YroVjSRh3v3YT6jsNPWn1w=s64","userId":"07304837105082415447"}},"outputId":"3a2faf11-5f53-45f2-8d3c-9e2d5a79e745","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Adjust default probability\n","probs = default_classifier['model'].predict_proba(data_dict12_strat['X_test'])[:,1]\n","\n","actual_default = sum(data_dict12_strat['y_test'])/len(data_dict12_strat['y_test'])\n","actual_not_default = 1 - actual_default\n","\n","print(\"Adjusting classifier for new default split. % Default:\",actual_default)\n","\n","A = probs/(train_default/actual_default)\n","B = (1 - probs)/(train_not_default/actual_not_default)\n","new_p = A/(A+B)\n","default_classifier['y_pred_probs'] = new_p"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Adjusting classifier for new default split. % Default: 0.1582\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ffDmv6S__1Nb"},"source":["## Predict return for Return-based strategy\n","for ret_col in return_regressor.keys():\n","  return_regressor[ret_col]['predicted_return'] = return_regressor[ret_col]['model'].predict(data_dict12_strat['X_test'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t1LasiLGIZU_"},"source":["## Predict return for Two-stage strategy\n","for ret_col in return_regressor_separate.keys():\n","  return_regressor_separate[ret_col]['predicted_regular_return'] = return_regressor_separate[ret_col]['model_0'].predict(data_dict12_strat['X_test'])\n","  return_regressor_separate[ret_col]['predicted_default_return'] = return_regressor_separate[ret_col]['model_1'].predict(data_dict12_strat['X_test'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WrV98AR6hSsa"},"source":["## 4.1 Random  <a name='sec4.1'/>\n","Compare with <a href=#sec5.1> section 5.1</a>: random rule on 2015-16 data"]},{"cell_type":"code","metadata":{"id":"rE6_qfFDBjTP"},"source":["strategy_results_12 = {}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"fgpvE3FChSsb","executionInfo":{"status":"ok","timestamp":1601343151758,"user_tz":240,"elapsed":1272,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"63d02bca-3666-454a-ac30-0c69115ef7c1","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb','ret_INTc','ret_Hybrid']\n","test_strategy = 'Random'\n","\n","print('strategy:',test_strategy)   \n","strat_random = test_investments(data_dict12_strat, strategy = test_strategy, \n","                            num_loans = 100, output_to_file = False, random_state = 1)\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(strat_random[ret_col]['average return']))\n","\n","strategy_results_12[test_strategy] = strat_random"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Random\n","ret_PESS: 0.028134580284846333\n","ret_OPT: 0.062012807044345655\n","ret_INTa: 0.042668948849952315\n","ret_INTb: 0.04933754530764588\n","ret_INTc: 0.09336684645216911\n","ret_Hybrid: 0.06876063211004313\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdgneSwvhSse"},"source":["## 4.2 Ranking   <a name='sec4.2'/>\n","Compare with <a href=#sec5.2> section 5.2</a>."]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":false,"id":"43nBNujZhSse","executionInfo":{"status":"ok","timestamp":1601343155645,"user_tz":240,"elapsed":1353,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"1db2fdbf-8ccc-43dd-e49c-6c2dbb2e5a0c","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["test_strategy = 'Ranking'\n","\n","print('strategy:',test_strategy)\n","strat_rank = test_investments(data_dict12_strat, classifier=default_classifier, strategy = test_strategy, \n","                        num_loans = 100, output_to_file = False)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(strat_rank[ret_col]['average return']))\n","\n","strategy_results_12[test_strategy] = strat_rank"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Ranking\n","ret_PESS: 0.025544841488884293\n","ret_OPT: 0.05827973005642629\n","ret_INTa: 0.024588527408662107\n","ret_INTb: 0.05251624513086491\n","ret_INTc: 0.07802492794807546\n","ret_Hybrid: 0.08400469238965051\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SC8D3fxphSsg"},"source":["## 4.3 Regression    <a name='sec4.3'/>\n","Compare with <a href=#sec5.3> section 5.3</a>."]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"OJ7L5ON3hSsh","executionInfo":{"status":"ok","timestamp":1601343162277,"user_tz":240,"elapsed":1005,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"95690d74-aa03-4bb9-a4a5-7acaed370a9d","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["test_strategy = 'Regression'\n","\n","print('strategy:',test_strategy)\n","strat_reg = test_investments(data_dict12_strat, regressor = return_regressor, strategy = test_strategy, \n","                        num_loans = 100)\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(strat_reg[ret_col]['average return']))\n","\n","strategy_results_12[test_strategy] = strat_reg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Regression\n","ret_PESS: 0.05833417378070244\n","ret_OPT: 0.07641893317356119\n","ret_INTa: 0.041181780747910054\n","ret_INTb: 0.0543015383177116\n","ret_INTc: 0.09406652707105648\n","ret_Hybrid: 0.07939607153786607\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9hG4fTZrhSsj"},"source":["## 4.4 Two Stage on 2012-2013 data  <a name='sec4.4'/>\n","Compare with <a href=#sec5.4> section 5.4</a>."]},{"cell_type":"code","metadata":{"id":"ygf5rfLlNbu-","executionInfo":{"status":"ok","timestamp":1601343186572,"user_tz":240,"elapsed":1575,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"bca4b7b5-f94f-4786-a20c-be84ecc76a6b","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# Test with score adjustment\n","test_strategy = 'Two-stage'\n","\n","print('strategy:',test_strategy)\n","two_stage = test_investments(data_dict12_strat, classifier = default_classifier, regressor = return_regressor_separate, \n","                             strategy = test_strategy, num_loans = 100)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(two_stage[ret_col]['average return']))\n","\n","strategy_results_12[test_strategy] = two_stage"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Two-stage\n","ret_PESS: 0.07782948706261758\n","ret_OPT: 0.08090653738800299\n","ret_INTa: 0.04304298697600049\n","ret_INTb: 0.046935009779937725\n","ret_INTc: 0.09384203613831926\n","ret_Hybrid: 0.07989612938912062\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5s3c0K2fEhzh"},"source":["## 4.5 Best Possible\n","\n","For benchmarking purposes only"]},{"cell_type":"code","metadata":{"id":"6xzs1Q_K5rVX","executionInfo":{"status":"ok","timestamp":1601343190111,"user_tz":240,"elapsed":1334,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"8aea89ef-0a3c-472e-bb81-5999ab8d6ed2","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["## Best Possible Strategy\n","# Test with score adjustment\n","test_strategy = 'Best Possible'\n","\n","print('strategy:',test_strategy)\n","best_possible = test_investments(data_dict12_strat,\n","                             strategy = test_strategy, num_loans = 100)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(best_possible[ret_col]['average return']))\n","\n","strategy_results_12[test_strategy] = best_possible"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Best Possible\n","ret_PESS: 0.14028712573194443\n","ret_OPT: 0.2252569619657012\n","ret_INTa: 0.1504809288190356\n","ret_INTb: 0.16764774012670441\n","ret_INTc: 0.19952427409743012\n","ret_Hybrid: 0.2179708407450863\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jn2iL-z7hSsp"},"source":["## 4.6 Rules Based on Decision Tree Output"]},{"cell_type":"code","metadata":{"id":"kBWyTdMpmumI","executionInfo":{"status":"ok","timestamp":1601343194232,"user_tz":240,"elapsed":1257,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"2d37d000-905a-4447-f163-9d645cfb9ae9","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["test_strategy = 'Tree-based'\n","\n","print('strategy: ', test_strategy)\n","tree_based = test_investments(data_dict12_strat, classifier = default_classifier,\n","                             strategy = test_strategy, num_loans = 100)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(tree_based[ret_col]['average return']))\n","\n","strategy_results_12[test_strategy] = tree_based"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy:  Tree-based\n","ret_PESS: 0.04377432220305408\n","ret_OPT: 0.06743952160238469\n","ret_INTa: 0.04015317685245277\n","ret_INTb: 0.056641506809918356\n","ret_INTc: 0.08680968252975639\n","ret_Hybrid: 0.07893672778667865\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QhgETLoyEmXW"},"source":["## Strategy Results (2012)"]},{"cell_type":"code","metadata":{"id":"nFd64Xb_5EL6","executionInfo":{"status":"ok","timestamp":1601343199229,"user_tz":240,"elapsed":1214,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"cfaf1cd8-714f-4ed7-8972-5b7ad77bcdbf","colab":{"base_uri":"https://localhost:8080/","height":646}},"source":["strategy_results_list = []\n","for s in strategy_results_12.keys():\n","  for ret_col in col_list:\n","    strategy_results_list.append([s, ret_col, (strategy_results_12[s][ret_col]['average return'])])\n","strategy_results12_df = pd.DataFrame(strategy_results_list, columns=['Strategy','Return Column','Avg Return'])\n","strategy_results12_df.sort_values(by=['Return Column','Strategy'], inplace=True)\n","print(strategy_results12_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["         Strategy Return Column  Avg Return\n","29  Best Possible    ret_Hybrid    0.217971\n","5          Random    ret_Hybrid    0.068761\n","11        Ranking    ret_Hybrid    0.084005\n","17     Regression    ret_Hybrid    0.079396\n","35     Tree-based    ret_Hybrid    0.078937\n","23      Two-stage    ret_Hybrid    0.079896\n","26  Best Possible      ret_INTa    0.150481\n","2          Random      ret_INTa    0.042669\n","8         Ranking      ret_INTa    0.024589\n","14     Regression      ret_INTa    0.041182\n","32     Tree-based      ret_INTa    0.040153\n","20      Two-stage      ret_INTa    0.043043\n","27  Best Possible      ret_INTb    0.167648\n","3          Random      ret_INTb    0.049338\n","9         Ranking      ret_INTb    0.052516\n","15     Regression      ret_INTb    0.054302\n","33     Tree-based      ret_INTb    0.056642\n","21      Two-stage      ret_INTb    0.046935\n","28  Best Possible      ret_INTc    0.199524\n","4          Random      ret_INTc    0.093367\n","10        Ranking      ret_INTc    0.078025\n","16     Regression      ret_INTc    0.094067\n","34     Tree-based      ret_INTc    0.086810\n","22      Two-stage      ret_INTc    0.093842\n","25  Best Possible       ret_OPT    0.225257\n","1          Random       ret_OPT    0.062013\n","7         Ranking       ret_OPT    0.058280\n","13     Regression       ret_OPT    0.076419\n","31     Tree-based       ret_OPT    0.067440\n","19      Two-stage       ret_OPT    0.080907\n","24  Best Possible      ret_PESS    0.140287\n","0          Random      ret_PESS    0.028135\n","6         Ranking      ret_PESS    0.025545\n","12     Regression      ret_PESS    0.058334\n","30     Tree-based      ret_PESS    0.043774\n","18      Two-stage      ret_PESS    0.077829\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aF1Vpf7yG8l2","executionInfo":{"status":"ok","timestamp":1601343203640,"user_tz":240,"elapsed":1395,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"589c68a1-fcc5-4dc5-ff9b-23dc8cea4cda","colab":{"base_uri":"https://localhost:8080/","height":417}},"source":["fig = px.bar(strategy_results12_df, x=\"Return Column\", y=\"Avg Return\",\n","             color='Strategy', barmode='group',\n","             height=400,title=\"2012 Strategy Results\")\n","fig.update_layout(legend=dict(\n","    orientation=\"h\",\n","    yanchor=\"bottom\",\n","    y=1.02,\n","    xanchor=\"right\",\n","    x=1\n","))\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"05a9911f-2a80-4af8-a167-749049fc723f\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"05a9911f-2a80-4af8-a167-749049fc723f\")) {\n","                    Plotly.newPlot(\n","                        '05a9911f-2a80-4af8-a167-749049fc723f',\n","                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Best Possible<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Best Possible\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"Strategy=Best Possible\", \"offsetgroup\": \"Strategy=Best Possible\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.2179708407450863, 0.1504809288190356, 0.16764774012670441, 0.19952427409743012, 0.2252569619657012, 0.14028712573194443], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Random<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Random\", \"marker\": {\"color\": \"#EF553B\"}, \"name\": \"Strategy=Random\", \"offsetgroup\": \"Strategy=Random\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.06876063211004313, 0.042668948849952315, 0.04933754530764588, 0.09336684645216911, 0.062012807044345655, 0.028134580284846333], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Ranking<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Ranking\", \"marker\": {\"color\": \"#00cc96\"}, \"name\": \"Strategy=Ranking\", \"offsetgroup\": \"Strategy=Ranking\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.08400469238965051, 0.024588527408662107, 0.05251624513086491, 0.07802492794807546, 0.05827973005642629, 0.025544841488884293], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Regression<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Regression\", \"marker\": {\"color\": \"#ab63fa\"}, \"name\": \"Strategy=Regression\", \"offsetgroup\": \"Strategy=Regression\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.07939607153786607, 0.041181780747910054, 0.0543015383177116, 0.09406652707105648, 0.07641893317356119, 0.05833417378070244], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Tree-based<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Tree-based\", \"marker\": {\"color\": \"#FFA15A\"}, \"name\": \"Strategy=Tree-based\", \"offsetgroup\": \"Strategy=Tree-based\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.07893672778667865, 0.04015317685245277, 0.056641506809918356, 0.08680968252975639, 0.06743952160238469, 0.04377432220305408], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Two-stage<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Two-stage\", \"marker\": {\"color\": \"#19d3f3\"}, \"name\": \"Strategy=Two-stage\", \"offsetgroup\": \"Strategy=Two-stage\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.07989612938912062, 0.04304298697600049, 0.046935009779937725, 0.09384203613831926, 0.08090653738800299, 0.07782948706261758], \"yaxis\": \"y\"}],\n","                        {\"barmode\": \"group\", \"height\": 400, \"legend\": {\"orientation\": \"h\", \"tracegroupgap\": 0, \"x\": 1, \"xanchor\": \"right\", \"y\": 1.02, \"yanchor\": \"bottom\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"2012 Strategy Results\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Return Column\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Avg Return\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('05a9911f-2a80-4af8-a167-749049fc723f');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"SiSkAI4EE0l0"},"source":["## Time Sensitivity (2012) (step 6)"]},{"cell_type":"code","metadata":{"id":"xEDlTvf-EzKW","executionInfo":{"status":"ok","timestamp":1601343233812,"user_tz":240,"elapsed":2526,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"50e9a190-3837-4fa2-c385-dfec78bb151c","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["result_sensitivity = []\n","\n","## Vary the portfolio size from 100 to 1000\n","# random_forest = rf07\n","for num_loans in list(range(100,1000,100)):\n","    reg_0 = test_investments(data_dict12_strat, regressor = return_regressor_separate, classifier = default_classifier, \n","                            strategy = 'Ranking', num_loans = num_loans)\n","    result_sensitivity.append(reg_0['ret_Hybrid']['average return'])\n","    \n","result_sensitivity = np.array(result_sensitivity) * 100\n","sns.pointplot(np.array(list(range(100,1000,100))),result_sensitivity)\n","sns.despine()\n","plt.ylabel('Investment Return (%)',size = 14)\n","plt.xlabel('Portfolio Size',size = 14)\n","plt.show()\n","\n","# Hybrid + Two-Stage - good chart\n","# Also show Hyrbid + Best Possible"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"SJbXaAwghSsq"},"source":["# Step 5- Sensitivity of the strategies across times\n","\n","Again, we downsampled the 2015 set earlier to make the default/non-default class balance, so we must re-build the 2015 dataset with the actual default/non-default split.\n","\n","We also must again run our models on this new dataset to obtain predictions, and adjust for class imbalance where necessary."]},{"cell_type":"code","metadata":{"id":"O98iALImhSsq"},"source":["## switch back to 2015-16 data\n","data = data15.copy()\n","\n","# Create the outcome\n","data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])\n","\n","# Create a feature for the length of a person's credit history at the\n","# time the loan is issued\n","data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n","\n","# Randomly assign each row to a training and test set. We do this now\n","# because we will be fitting a variety of models on various time periods,\n","# and we would like every period to use the *same* training/test split\n","np.random.seed(default_seed)\n","data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])\n","\n","# Create a matrix of features and outcomes, with dummies. Record the\n","# names of the dummies for later use\n","X_continuous = data[continuous_features].values\n","\n","X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n","discrete_features_dummies = X_discrete.columns.tolist()\n","X_discrete = X_discrete.values\n","\n","X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n","\n","y = data.outcome.values\n","\n","train = data.train.values\n","\n","final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n","all_features = pd.Series(continuous_features + discrete_features_dummies)\n","idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n","                                                     if j.split(\"::\")[0] in final_features]\n","\n","## useful when choosing the most significant features\n","selected_features = all_features[idx]\n","selected_features.reset_index(drop=True,inplace=True)\n","selected_features15 = selected_features.copy()\n","\n","## Process data here:\n","# prepare data \n","start_date_train = datetime.date(2015,1,1)\n","end_date_train = datetime.date(2015,9,1)\n","start_date_test = datetime.date(2015,10,1)\n","end_date_test = datetime.date(2015,12,1)\n","\n","data_dict15_strat = prepare_data(data_subset = np.array([True]*np.array([True]*len(data))),\n","                              date_range_train = (start_date_train, end_date_train),\n","                         date_range_test = (start_date_test, end_date_test),\n","                         n_samples_train = 20000, n_samples_test = 10000, feature_subset = final_features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J5QsFkLDDeRu"},"source":["# Choose the default classifier\n","default_classifier15 = saved_models['l1_logistic07'].copy()\n","\n","# Choose the return regressor\n","return_regressor15 = saved_models['reg_rf12'].copy()\n","\n","## Choose the split return regressor\n","return_regressor_separate15 = saved_models['reg_rf12_df'].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RzMlLuuDpP0"},"source":["## Adjust for class balance change\n","probs = default_classifier15['model'].predict_proba(data_dict15_strat['X_test'])[:,1]\n","\n","actual_default = sum(data_dict15_strat['y_test'])/len(data_dict15_strat['y_test'])\n","actual_not_default = 1 - actual_default\n","\n","A = probs/(train_default/actual_default)\n","B = (1 - probs)/(train_not_default/actual_not_default)\n","new_p = A/(A+B)\n","default_classifier15['y_pred_probs'] = new_p"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcyaEcbrDuM8"},"source":["## Predict return for Return-based strategy\n","for ret_col in return_regressor15.keys():\n","  return_regressor15[ret_col]['predicted_return'] = return_regressor[ret_col]['model'].predict(data_dict15_strat['X_test'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fphXngNXJfG4"},"source":["## Predict return for two-stage strategy\n","for ret_col in return_regressor_separate15.keys():\n","  return_regressor_separate15[ret_col]['predicted_regular_return'] = return_regressor_separate15[ret_col]['model_0'].predict(data_dict15_strat['X_test'])\n","  return_regressor_separate15[ret_col]['predicted_default_return'] = return_regressor_separate15[ret_col]['model_1'].predict(data_dict15_strat['X_test'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrPGdsYkhSsu"},"source":["### 5.1 Random <a name = 'sec5.1' />\n","Compare with <a href=#sec4.1>section 4.1</a>: random rule applied on 2012-2013 data"]},{"cell_type":"code","metadata":{"id":"CELDiXxsGHHX"},"source":["strategy_results_15 = {}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8KgvYJfhSsu","executionInfo":{"status":"ok","timestamp":1601343797998,"user_tz":240,"elapsed":1161,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"828a7e31-5a45-475f-c2c5-23c8972795f0","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb','ret_INTc','ret_Hybrid']\n","test_strategy = 'Random'\n","\n","print('strategy:',test_strategy)   \n","strat_random = test_investments(data_dict15_strat, strategy = test_strategy, \n","                            num_loans = 100, output_to_file = False, random_state = 1)\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(strat_random[ret_col]['average return']))\n","\n","strategy_results_15[test_strategy] = strat_random"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Random\n","ret_PESS: 0.014995600816745315\n","ret_OPT: 0.05358572908874967\n","ret_INTa: 0.02207658613416822\n","ret_INTb: 0.03088410279834291\n","ret_INTc: 0.05823993500173976\n","ret_Hybrid: 0.06306924501922306\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DQf_ZCtfhSsv"},"source":["### 5.2 Ranking  <a name = 'sec5.2' />\n","Compare with <a href=#sec4.2>section 4.2</a>: ranking applied on 2012-2013 data"]},{"cell_type":"code","metadata":{"id":"mUAVxCwxhSsw","executionInfo":{"status":"ok","timestamp":1601343803141,"user_tz":240,"elapsed":1800,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"20359d09-7af7-43f2-b744-14890ec3d261","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# load the random forest model if you haven't yet\n","# rf07 = saved_models['rf07']\n","\n","test_strategy = 'Ranking'\n","\n","print('strategy:',test_strategy)\n","strat_rank = test_investments(data_dict15_strat, classifier=default_classifier15, strategy = test_strategy, \n","                        num_loans = 100, output_to_file = False)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(strat_rank[ret_col]['average return']))\n","\n","strategy_results_15[test_strategy] = strat_rank"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Ranking\n","ret_PESS: 0.019710812719464208\n","ret_OPT: 0.035489050568630685\n","ret_INTa: 0.021778703249817333\n","ret_INTb: 0.020316179744942885\n","ret_INTc: 0.06673755757159328\n","ret_Hybrid: 0.05951975552741091\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gdkAVCR5hSsx"},"source":["### 5.3 Regression  <a name = 'sec5.3' />\n","Compare with <a href=#sec4.3>section 4.3</a>: regression rule applied on 2012-2013 data"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"OyWM_kwNhSsx","executionInfo":{"status":"ok","timestamp":1601343808575,"user_tz":240,"elapsed":1424,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"0ff9faa4-1fee-4d3d-ab2a-0f84b7b2af11","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["test_strategy = 'Regression'\n","\n","print('strategy:',test_strategy)\n","strat_reg = test_investments(data_dict15_strat, regressor = return_regressor15, strategy = test_strategy, \n","                        num_loans = 100)\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(strat_reg[ret_col]['average return']))\n","\n","strategy_results_15[test_strategy] = strat_reg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Regression\n","ret_PESS: 0.018459049696727917\n","ret_OPT: 0.039150044936557826\n","ret_INTa: 0.020601831916734547\n","ret_INTb: 0.026669780656008498\n","ret_INTc: 0.062488565964642376\n","ret_Hybrid: 0.052454585494394614\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lhOI6U28hSsz"},"source":["### 5.4 Two-stage  <a name = 'sec5.4' />\n","Compare with <a href=#sec4.4>section 4.4</a>: two-stage rule applied on 2012-2013 data"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"8c8GCZRchSsz","executionInfo":{"status":"ok","timestamp":1601343814213,"user_tz":240,"elapsed":1176,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"0b73fe55-7583-4622-ea34-4b6ba4f9e1ef","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# load the model if you haven't yet\n","# reg_rf_separate13 = saved_models['reg_rf_separate13']\n","\n","test_strategy = 'Two-stage'\n","\n","print('strategy:',test_strategy)\n","two_stage = test_investments(data_dict15_strat, classifier = default_classifier15, regressor = return_regressor_separate15, \n","                             strategy = test_strategy, num_loans = 100)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(two_stage[ret_col]['average return']))\n","\n","strategy_results_15[test_strategy] = two_stage"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Two-stage\n","ret_PESS: 0.037871921478264764\n","ret_OPT: 0.029862104221746268\n","ret_INTa: 0.02338539279049063\n","ret_INTb: 0.039322997091251984\n","ret_INTc: 0.06265362447338524\n","ret_Hybrid: 0.06790429343300272\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WDI8SyaNEYfp"},"source":["## 5.5 Best Possible\n","\n","For benchmarking purposes only."]},{"cell_type":"code","metadata":{"id":"jwN24gN6EJ6z","executionInfo":{"status":"ok","timestamp":1601343819016,"user_tz":240,"elapsed":1768,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"79583767-a912-4b68-9bce-e6ae1f3ca126","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["## Best Possible Strategy\n","# Test with score adjustment\n","test_strategy = 'Best Possible'\n","\n","print('strategy:',test_strategy)\n","best_possible = test_investments(data_dict15_strat,\n","                             strategy = test_strategy, num_loans = 100)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(best_possible[ret_col]['average return']))\n","\n","strategy_results_15[test_strategy] = best_possible"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy: Best Possible\n","ret_PESS: 0.11752259436168179\n","ret_OPT: 0.23628577617036853\n","ret_INTa: 0.12269478913716722\n","ret_INTb: 0.14050526796199758\n","ret_INTc: 0.17380966929853348\n","ret_Hybrid: 0.229722279203288\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YNOMleIuoEMP"},"source":["## 5.6 Rules Based on Decision Tree Output"]},{"cell_type":"code","metadata":{"id":"yJdOvQWcoMoM","executionInfo":{"status":"ok","timestamp":1601343823309,"user_tz":240,"elapsed":1602,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"b659e77d-6e8a-4584-fe74-695ed1f4db2e","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["test_strategy = 'Tree-based'\n","\n","print('strategy: ', test_strategy)\n","tree_based = test_investments(data_dict15_strat, classifier = default_classifier15,\n","                             strategy = test_strategy, num_loans = 100)\n","\n","for ret_col in col_list:\n","    print(ret_col + ': ' + str(tree_based[ret_col]['average return']))\n","\n","strategy_results_15[test_strategy] = tree_based"],"execution_count":null,"outputs":[{"output_type":"stream","text":["strategy:  Tree-based\n","ret_PESS: 0.029613596543002076\n","ret_OPT: 0.05782744636567425\n","ret_INTa: 0.030340257318357485\n","ret_INTb: 0.046692135170984556\n","ret_INTc: 0.07665453428060616\n","ret_Hybrid: 0.06915633559198078\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NRfzoe7BGe9z"},"source":["## Strategy Results (2015)"]},{"cell_type":"code","metadata":{"id":"AFZMzATIGgkg","executionInfo":{"status":"ok","timestamp":1601343827214,"user_tz":240,"elapsed":946,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"47218ce5-51f0-4f47-8ef4-9dc95a7bb8d3","colab":{"base_uri":"https://localhost:8080/","height":646}},"source":["strategy_results_list = []\n","for s in strategy_results_15.keys():\n","  for ret_col in col_list:\n","    strategy_results_list.append([s, ret_col, (strategy_results_15[s][ret_col]['average return'])])\n","strategy_results15_df = pd.DataFrame(strategy_results_list, columns=['Strategy','Return Column','Avg Return'])\n","strategy_results15_df.sort_values(by=['Return Column','Strategy'], inplace=True)\n","print(strategy_results15_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["         Strategy Return Column  Avg Return\n","29  Best Possible    ret_Hybrid    0.229722\n","5          Random    ret_Hybrid    0.063069\n","11        Ranking    ret_Hybrid    0.059520\n","17     Regression    ret_Hybrid    0.052455\n","35     Tree-based    ret_Hybrid    0.069156\n","23      Two-stage    ret_Hybrid    0.067904\n","26  Best Possible      ret_INTa    0.122695\n","2          Random      ret_INTa    0.022077\n","8         Ranking      ret_INTa    0.021779\n","14     Regression      ret_INTa    0.020602\n","32     Tree-based      ret_INTa    0.030340\n","20      Two-stage      ret_INTa    0.023385\n","27  Best Possible      ret_INTb    0.140505\n","3          Random      ret_INTb    0.030884\n","9         Ranking      ret_INTb    0.020316\n","15     Regression      ret_INTb    0.026670\n","33     Tree-based      ret_INTb    0.046692\n","21      Two-stage      ret_INTb    0.039323\n","28  Best Possible      ret_INTc    0.173810\n","4          Random      ret_INTc    0.058240\n","10        Ranking      ret_INTc    0.066738\n","16     Regression      ret_INTc    0.062489\n","34     Tree-based      ret_INTc    0.076655\n","22      Two-stage      ret_INTc    0.062654\n","25  Best Possible       ret_OPT    0.236286\n","1          Random       ret_OPT    0.053586\n","7         Ranking       ret_OPT    0.035489\n","13     Regression       ret_OPT    0.039150\n","31     Tree-based       ret_OPT    0.057827\n","19      Two-stage       ret_OPT    0.029862\n","24  Best Possible      ret_PESS    0.117523\n","0          Random      ret_PESS    0.014996\n","6         Ranking      ret_PESS    0.019711\n","12     Regression      ret_PESS    0.018459\n","30     Tree-based      ret_PESS    0.029614\n","18      Two-stage      ret_PESS    0.037872\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uv6tzSvAHUBv","executionInfo":{"status":"ok","timestamp":1601343830333,"user_tz":240,"elapsed":1814,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"78d63a98-8b4b-4142-95df-613378ee9361","colab":{"base_uri":"https://localhost:8080/","height":417}},"source":["fig = px.bar(strategy_results15_df, x=\"Return Column\", y=\"Avg Return\",\n","             color='Strategy', barmode='group',\n","             height=400,title=\"2015 Strategy Results\")\n","fig.update_layout(legend=dict(\n","    orientation=\"h\",\n","    yanchor=\"bottom\",\n","    y=1.02,\n","    xanchor=\"right\",\n","    x=1\n","))\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"2ee67e76-c3ee-4db1-b1a9-51553688077d\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"2ee67e76-c3ee-4db1-b1a9-51553688077d\")) {\n","                    Plotly.newPlot(\n","                        '2ee67e76-c3ee-4db1-b1a9-51553688077d',\n","                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Best Possible<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Best Possible\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"Strategy=Best Possible\", \"offsetgroup\": \"Strategy=Best Possible\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.229722279203288, 0.12269478913716722, 0.14050526796199758, 0.17380966929853348, 0.23628577617036853, 0.11752259436168179], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Random<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Random\", \"marker\": {\"color\": \"#EF553B\"}, \"name\": \"Strategy=Random\", \"offsetgroup\": \"Strategy=Random\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.06306924501922306, 0.02207658613416822, 0.03088410279834291, 0.05823993500173976, 0.05358572908874967, 0.014995600816745315], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Ranking<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Ranking\", \"marker\": {\"color\": \"#00cc96\"}, \"name\": \"Strategy=Ranking\", \"offsetgroup\": \"Strategy=Ranking\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.05951975552741091, 0.021778703249817333, 0.020316179744942885, 0.06673755757159328, 0.035489050568630685, 0.019710812719464208], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Regression<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Regression\", \"marker\": {\"color\": \"#ab63fa\"}, \"name\": \"Strategy=Regression\", \"offsetgroup\": \"Strategy=Regression\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.052454585494394614, 0.020601831916734547, 0.026669780656008498, 0.062488565964642376, 0.039150044936557826, 0.018459049696727917], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Tree-based<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Tree-based\", \"marker\": {\"color\": \"#FFA15A\"}, \"name\": \"Strategy=Tree-based\", \"offsetgroup\": \"Strategy=Tree-based\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.06915633559198078, 0.030340257318357485, 0.046692135170984556, 0.07665453428060616, 0.05782744636567425, 0.029613596543002076], \"yaxis\": \"y\"}, {\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Strategy=Two-stage<br>Return Column=%{x}<br>Avg Return=%{y}\", \"legendgroup\": \"Strategy=Two-stage\", \"marker\": {\"color\": \"#19d3f3\"}, \"name\": \"Strategy=Two-stage\", \"offsetgroup\": \"Strategy=Two-stage\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"ret_Hybrid\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\", \"ret_OPT\", \"ret_PESS\"], \"xaxis\": \"x\", \"y\": [0.06790429343300272, 0.02338539279049063, 0.039322997091251984, 0.06265362447338524, 0.029862104221746268, 0.037871921478264764], \"yaxis\": \"y\"}],\n","                        {\"barmode\": \"group\", \"height\": 400, \"legend\": {\"orientation\": \"h\", \"tracegroupgap\": 0, \"x\": 1, \"xanchor\": \"right\", \"y\": 1.02, \"yanchor\": \"bottom\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"2015 Strategy Results\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Return Column\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Avg Return\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('2ee67e76-c3ee-4db1-b1a9-51553688077d');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"9zwSJNhPhSs2"},"source":["# Step 6-  Sensitivity test of portfolio size (2015)"]},{"cell_type":"code","metadata":{"button":false,"new_sheet":false,"pycharm":{"name":"#%%\n"},"run_control":{"read_only":false},"id":"IoxQysTAhSs2","executionInfo":{"status":"ok","timestamp":1601344005012,"user_tz":240,"elapsed":2578,"user":{"displayName":"Kristina Schiffhauer","photoUrl":"","userId":"06065681507244458394"}},"outputId":"ccf55bc3-9bdc-4ed3-a872-bc81f3b09642","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["## Note - this will only work for the 2015 dataset - 2012 sensitivity is at the end of section 4\n","result_sensitivity = []\n","\n","## Vary the portfolio size from 100 to 1000\n","for num_loans in list(range(100,1000,100)):\n","    reg_0 = test_investments(data_dict15_strat, regressor = return_regressor_separate, classifier = default_classifier15, \n","                            strategy = 'Two-stage', num_loans = num_loans)\n","    result_sensitivity.append(reg_0['ret_Hybrid']['average return'])\n","    \n","result_sensitivity = np.array(result_sensitivity) * 100\n","sns.pointplot(np.array(list(range(100,1000,100))),result_sensitivity)\n","sns.despine()\n","plt.ylabel('Investment Return (%)',size = 14)\n","plt.xlabel('Portfolio Size',size = 14)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"BgYvhBVIhSs5"},"source":["## Step 7. Save the models in one file."]},{"cell_type":"code","metadata":{"id":"nvE_NVWZhSs5"},"source":["# save all time-consuming models in one dict_ \n","# models_to_save['reg_rf13'] = reg_rf13\n","# models_to_save['reg_rf07'] = reg_rf07\n","# ... etc."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"az3HFQ3vhSs7"},"source":["## os.path.abspath(os.getcwd()) # get current directory\n","#filename = '/Users/su.jia/Box/LendingClub BigData2018/Su/saved_models/week4_saved_models'\n","\n","path = root_dir + \"/saved_models/week4_saved_models\"   \n","\n","outfile = open(path,'wb')\n","pickle.dump(models_to_save, outfile)\n","outfile.close()"],"execution_count":null,"outputs":[]}]}