{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Purchase_Prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpmarsha/ML2AmazonKaggle/blob/master/Purchase_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhoMne-G7ID4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install mxnet\n",
        "# !pip install d2l\n",
        "import pandas as pd\n",
        "from mxnet import gluon, np, npx, autograd\n",
        "from mxnet.gluon import nn\n",
        "import d2l\n",
        "import mxnet as mx\n",
        "npx.set_np()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvibhDAv7ID7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read user and items into a dataframe which is then converted into csv\n",
        "# this part takes a while and is only done ONCE\n",
        "# after creating csv, we can upload that into a dataframe directly\n",
        "\n",
        "#def read_file(f):\n",
        " #   for l in open(f):\n",
        " #       yield eval(l)\n",
        "#df = pd.DataFrame()\n",
        "\n",
        "#for l in read_file(\"train.json\"):\n",
        " #   reviewerID,itemID = l['reviewerID'],l['itemID']\n",
        " #   df = df.append({'reviewerID': reviewerID, 'itemID': itemID}, ignore_index = True)\n",
        "#df.to_csv(\"train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fbeVC687S0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4d6f9254-a785-4434-c3c0-e0f5dcd5b328"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tih8fzpO7ID9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we can upload csv straight into dataframe\n",
        "root_path = '/content/drive/My Drive/Team 3 Kaggle Competition ML2/'\n",
        "data = pd.read_csv(root_path+\"train_PurchasePrediction.csv\")\n",
        "data = data.drop(data.columns[0], axis=1)  # drop the unnamed column\n",
        "# check to see if there are any duplicate users + items\n",
        "len(data[data.duplicated()])\n",
        "# add a column to indicate item was purchased\n",
        "data['Purchased'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZshU-0t7ID_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to speed things up, working with 1000 rows for now..need to remove this part later\n",
        "data = data.drop(data.index[1000:]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jda-tPdI7IEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create pivot table to show every reviewerID and every itemID\n",
        "# this will allow us identify users who did not purchase an item as well\n",
        "df_matrix = pd.pivot_table(data, values='Purchased', index='reviewerID', columns='itemID')\n",
        "df_matrix = df_matrix.reset_index()\n",
        "# undo pivot table and save it as data\n",
        "data = pd.melt(df_matrix, id_vars=['reviewerID'], value_name='Purchased')  # this takes some time to run\n",
        "data = data.fillna(0)  # replace NaN with 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPHF9qHA7IED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_users = data[\"reviewerID\"].unique().shape[0]\n",
        "num_items = data[\"itemID\"].unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL1uWdha7IEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# since we need our data to be numeric, extracting numerics\n",
        "# KEEP THIS IN MIND WHEN GENERATING PREDICTIONS FOR TEST SET\n",
        "data['reviewerID'] = data['reviewerID'].str.extract('(\\d+)')\n",
        "data['itemID'] = data['itemID'].str.extract('(\\d+)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdR9pkJU7IEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split data into train and validation set, ensuring equal proportion of labels in both\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "def train_validate_split(data, train_size=0.8, validate_size=0.2):\n",
        "    # first we shuffle and split all data into train and test set with equal label proportions\n",
        "    sss = StratifiedShuffleSplit(n_splits = 1, train_size = train_size)\n",
        "    for train_index, validate_index in sss.split(data, data['Purchased']):\n",
        "        train, validate = data.iloc[train_index, : ], data.iloc[validate_index, : ]\n",
        "    return(train, validate)\n",
        "\n",
        "train, validate = train_validate_split(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej-QZxot7IEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_u, train_i, train_p = np.array(train['reviewerID'], dtype = 'float32'), np.array(train['itemID'], dtype = 'float32'), np.array(train['Purchased'], dtype = 'float32')\n",
        "validate_u, validate_i, validate_p = np.array(validate['reviewerID'], dtype = 'float32'), np.array(validate['itemID'], dtype = 'float32'), np.array(validate['Purchased'], dtype = 'float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfPIducX7IEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = gluon.data.ArrayDataset(train_u, train_i, train_p)\n",
        "train_iter = gluon.data.DataLoader(train_set, shuffle=True, last_batch='rollover',batch_size=256)\n",
        "\n",
        "validate_set = gluon.data.ArrayDataset(validate_u, validate_i, validate_p)\n",
        "validate_iter = gluon.data.DataLoader(validate_set, shuffle=False, last_batch='rollover',batch_size=256)\n",
        "\n",
        "class MF_user_item_bias(nn.Block):\n",
        "    def __init__(self, num_factors, num_users, num_items, **kwargs):\n",
        "        super(MF_user_item_bias, self).__init__(**kwargs)\n",
        "        self.P = nn.Embedding(input_dim=num_users, output_dim=num_factors)\n",
        "        self.Q = nn.Embedding(input_dim=num_items, output_dim=num_factors)\n",
        "        self.user_bias = nn.Embedding(num_users, 1)\n",
        "        self.item_bias = nn.Embedding(num_items, 1)\n",
        "\n",
        "    def forward(self, user_id, item_id):\n",
        "        P_u = self.P(user_id)\n",
        "        Q_i = self.Q(item_id)\n",
        "        b_u = self.user_bias(user_id)\n",
        "        b_i = self.item_bias(item_id)\n",
        "        outputs = (P_u * Q_i).sum(axis=1) + np.squeeze(b_u) + np.squeeze(b_i)\n",
        "        return outputs.flatten()\n",
        "\n",
        "def evaluator(net, test_iter, ctx):\n",
        "    rmse = mx.metric.RMSE()  # Get the RMSE\n",
        "    rmse_list = []\n",
        "    for idx, (users, items, ratings) in enumerate(test_iter):\n",
        "        u = gluon.utils.split_and_load(users, ctx, even_split=False)\n",
        "        i = gluon.utils.split_and_load(items, ctx, even_split=False)\n",
        "        r_ui = gluon.utils.split_and_load(ratings, ctx, even_split=False)\n",
        "        r_hat = [net(u, i) for u, i in zip(u, i)]\n",
        "        rmse.update(labels=r_ui, preds=r_hat)\n",
        "        rmse_list.append(rmse.get()[1])\n",
        "    return float(np.mean(np.array(rmse_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlOA9THk7IEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model for user and item only\n",
        "ctx = d2l.try_all_gpus()\n",
        "ctx_list=d2l.try_all_gpus()\n",
        "net = MF_user_item_bias(30, num_users, num_items)\n",
        "net.initialize(ctx=ctx, force_reinit=True, init=mx.init.Normal(0.01))\n",
        "lr, num_epochs, wd, optimizer = 0.002, 30, 1e-5, 'adam'\n",
        "loss = gluon.loss.L2Loss()\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer,{\"learning_rate\": lr, 'wd': wd})\n",
        "    \n",
        "for epoch in range(num_epochs):\n",
        "    l = 0\n",
        "    metric = d2l.Accumulator(3)\n",
        "    for i, values in enumerate(train_iter):\n",
        "        input_data = []  # 3 arrays: train_u, train_i, train_p\n",
        "        values = values if isinstance(values, list) else [values]\n",
        "        for v in values:\n",
        "            input_data.append(gluon.utils.split_and_load(v, ctx_list))\n",
        "        train_feat = input_data[0:-1] if len(values) > 1 else input_data   # 2 arrays: train_u, train_i\n",
        "        train_label = input_data[-1]  # train_p\n",
        "        with autograd.record():\n",
        "            preds = [net(*t) for t in zip(*train_feat)]\n",
        "            ls = [loss(p, s) for p, s in zip(preds, train_label)]\n",
        "        [l.backward() for l in ls]\n",
        "        l += sum([l.asnumpy() for l in ls]).mean() / len(ctx_list)\n",
        "        trainer.step(values[0].shape[0])\n",
        "        metric.add(l, values[0].shape[0], values[0].size)\n",
        "    train_l = l / (i + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw9koppN7IEP",
        "colab_type": "code",
        "outputId": "87207d87-c1ea-4341-caae-f316a0df6b9d",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(net, data_iter):\n",
        "    metric = Accumulator(2)  # num_corrected_examples, num_examples\n",
        "    for i, values in enumerate(train_iter):\n",
        "        input_data = []  # 3 arrays: train_u, train_i, train_p\n",
        "        values = values if isinstance(values, list) else [values]\n",
        "        for v in values:\n",
        "            input_data.append(gluon.utils.split_and_load(v, ctx_list))\n",
        "        train_feat = input_data[0:-1] if len(values) > 1 else input_data   # 2 arrays: train_u, train_i\n",
        "        train_label = input_data[-1]  # train_p\n",
        "        preds = [net(*t) for t in zip(*train_feat)]\n",
        "        metric.add(d2l.accuracy(np.array(preds), np.array(train_label), np.array(train_label).size))\n",
        "        metric[0] / metric[1]\n",
        "\n",
        "d2l.evaluate_accuracy(net, train_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "float division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-2772d17e2c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/miniconda3/envs/d2l/lib/python3.7/site-packages/d2l/d2l.py\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(net, data_iter)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcMp0rcQ7IEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcdBZLot7IEW",
        "colab_type": "code",
        "outputId": "c29914aa-2c34-47ec-e4cc-329b7c6fe349",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjnql7i87IEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWy6RmiR7IEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgD7vg2K7IEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCkZMBwa7IEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50AjsTcR7IEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymX3MFPs7IEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUKrzP9b7IEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6kY3-rX7IEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK54fLZY7IEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ8SYGo_7IEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}