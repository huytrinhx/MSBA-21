{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tpmarsha/ML2AmazonKaggle/blob/master/Purchase_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhoMne-G7ID4"
   },
   "outputs": [],
   "source": [
    "#!pip install mxnet\n",
    "#!pip install d2l\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvibhDAv7ID7"
   },
   "outputs": [],
   "source": [
    "# read user and items into a dataframe which is then converted into csv\n",
    "# this part takes a while and is only done ONCE\n",
    "# after creating csv, we can upload that into a dataframe directly\n",
    "\n",
    "#def read_file(f):\n",
    " #   for l in open(f):\n",
    " #       yield eval(l)\n",
    "#df = pd.DataFrame()\n",
    "\n",
    "#for l in read_file(\"train.json\"):\n",
    " #   reviewerID,itemID = l['reviewerID'],l['itemID']\n",
    " #   df = df.append({'reviewerID': reviewerID, 'itemID': itemID}, ignore_index = True)\n",
    "#df.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1591553488201,
     "user": {
      "displayName": "Dipali Mistri",
      "photoUrl": "",
      "userId": "14112564951328525400"
     },
     "user_tz": 240
    },
    "id": "3fbeVC687S0N",
    "outputId": "40b47d28-b666-46fd-ab29-d0d1c2233f28"
   },
   "outputs": [],
   "source": [
    "# import data straight from csv that was created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1591553489299,
     "user": {
      "displayName": "Dipali Mistri",
      "photoUrl": "",
      "userId": "14112564951328525400"
     },
     "user_tz": 240
    },
    "id": "Tih8fzpO7ID9",
    "outputId": "b095177b-4303-4f9d-de3a-3e5b42a96706"
   },
   "outputs": [],
   "source": [
    "# now we can upload csv straight into dataframe\n",
    "path = \"/Users/dipali/Desktop/CMU MSBA/machine_learning_2/final_project/\"\n",
    "data = pd.read_csv(path+\"train.csv\")\n",
    "data = data.drop(data.columns[0], axis=1)  # drop the unnamed column\n",
    "# check to see if there are any duplicate users + items\n",
    "len(data[data.duplicated()])\n",
    "# add a column to indicate item was purchased\n",
    "data['Purchased'] = 1\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1591553490357,
     "user": {
      "displayName": "Dipali Mistri",
      "photoUrl": "",
      "userId": "14112564951328525400"
     },
     "user_tz": 240
    },
    "id": "QZshU-0t7ID_",
    "outputId": "106fc8de-bb0f-47df-b060-3a0da1d5f87c"
   },
   "outputs": [],
   "source": [
    "customers = list(numpy.sort(data.reviewerID.unique())) # Get our unique customers\n",
    "products = list(data.itemID.unique()) # Get our unique products that were purchased\n",
    "quantity = list(data.Purchased) # All of our purchases\n",
    "\n",
    "len(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sparse matrix\n",
    "rows = data.reviewerID.astype('category').cat.codes \n",
    "cols = data.itemID.astype('category').cat.codes \n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))\n",
    "purchases_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign indices to item and reviewer and add them to dataframe\n",
    "data['item_indices'] = data.itemID.astype('category').cat.codes\n",
    "data['reviewer_indices'] = data.reviewerID.astype('category').cat.codes\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sparsity\n",
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity_original = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity_original  # extremely sparse\n",
    "\n",
    "# from d2l textbook: A viable solution is to use additional side information such as user/item features to alleviate the sparsity\n",
    "\n",
    "training_set = purchases_sparse.copy() # Make a copy of the original data we can alter as our training set\n",
    "test_set = purchases_sparse.copy() # Make a copy of the original set to be the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the interactions within the sparse matrix and zip them together\n",
    "nonzero_inds = training_set.nonzero()\n",
    "nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) \n",
    "len(nonzero_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 20% of users with a purchase, mask their item purchases (turn label to 0's) in training data, save them for testing\n",
    "import random\n",
    "num_samples = int(numpy.ceil(0.20*len(nonzero_pairs)))\n",
    "samples = random.sample(nonzero_pairs, num_samples) # randomly select 20% to be in the test set\n",
    "user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "\n",
    "# store the users saved for testing into a list\n",
    "users_altered = list(set(user_inds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply matrix factorization\n",
    "# alternating least squares approximates user feature vec + item feature vec, meant to determine items to recommend\n",
    "# optimize parameter on the loss. not sure how to apply a grid search to find the best hyperparameters because i'm unable to extract the loss from the widget below, so i re-ran a bunch of times\n",
    "\n",
    "#!pip install implicit\n",
    "import implicit\n",
    "# apply model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=5, regularization=150, iterations=50,num_threads=1,calculate_training_loss=True)\n",
    "alpha_val = 50\n",
    "data_conf = (training_set * alpha_val).astype('double')\n",
    "model.fit(data_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for each user-item\n",
    "# higher prediction value = user-item pair strongly predicted to interact\n",
    "user_vecs = model.item_factors\n",
    "item_vecs = model.user_factors\n",
    "predictions = [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)]\n",
    "item_vecs = predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for each user who was masked in training\n",
    "# evaluate the performance by mean recall at k, mean precision at k, mean accuracy at k (where k is top x items)\n",
    "\n",
    "\n",
    "top_x_items = int(len(products)*0.20)  # play around with this number\n",
    "\n",
    "recall = []\n",
    "precision = []\n",
    "accuracy = []\n",
    "\n",
    "for user in users_altered: # Iterate through each user that had an item altered\n",
    "    training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "    zero_inds = numpy.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "    # Get the predicted values based on our user/item vectors\n",
    "    user_vec = predictions[0][user,:]\n",
    "    pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "    # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "    actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "    \n",
    "    # get top x items with highest prediction scores\n",
    "    top_indices = numpy.argsort(pred)[::-1][:top_x_items]   \n",
    "    pred2 = numpy.zeros(actual.shape)\n",
    "    for i in top_indices:    # make top x items 1's and the rest of items as 0's\n",
    "        pred2[i] = 1\n",
    "    pred2 = pred2[:top_x_items]\n",
    "    actual = actual[:top_x_items]\n",
    "    \n",
    "    recall.append(recall_score(actual,pred2))\n",
    "    precision.append(precision_score(actual,pred2))\n",
    "    accuracy.append(accuracy_score(actual,pred2))\n",
    "      \n",
    "print('mean recall at k: %f, mean precision at k: %f, mean accuracy at k: %f'% (numpy.mean(recall), \n",
    "                                                                                numpy.mean(precision), \n",
    "                                                                                numpy.mean(accuracy)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify top items by item index\n",
    "pop_items = data[['item_indices', 'Purchased']]\n",
    "pop_items = pop_items.groupby('item_indices').sum().reset_index()\n",
    "pop_items = pop_items.nlargest(3000, 'Purchased')   # most popular items\n",
    "pop_items = pop_items['item_indices'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the test data\n",
    "test_data = pd.read_csv(\"/Users/dipali/Desktop/CMU MSBA/machine_learning_2/final_project/pairs_Purchase.txt\")\n",
    "test_data = pd.DataFrame(test_data['reviewerID-itemID'].str.split(\"-\",expand=True))\n",
    "test_data.columns = 'reviewerID', 'itemID'\n",
    "\n",
    "# find corresponding item and reviewer indices which were determined earlier\n",
    "data2 = data.drop(columns = ['itemID', 'Purchased', 'item_indices'])\n",
    "data2 = data2.drop_duplicates()\n",
    "data3 = data.drop(columns = ['reviewerID', 'Purchased', 'reviewer_indices'])\n",
    "data3 = data3.drop_duplicates()\n",
    "\n",
    "# one dataframe of test set with reviewerid, itemid, and indices\n",
    "test_data = test_data[['reviewerID', 'itemID']].merge(data2[['reviewerID', 'reviewer_indices']], on='reviewerID', how='left')\n",
    "test_data = test_data[['reviewerID', 'itemID', 'reviewer_indices']].merge(data3[['itemID', 'item_indices']], on='itemID', how='left')\n",
    "\n",
    "# if NaN (reviewer or item did not exist in the test set), assign them to a random value: '123456'\n",
    "test_data[\"reviewer_indices\"] = test_data[\"reviewer_indices\"].fillna(123456)\n",
    "test_data[\"item_indices\"] = test_data[\"item_indices\"].fillna(123456)\n",
    "\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "# 2 methods: 1) for users who do not exist in test set, set all their predictions to 0 OR 2) set their prediction to 1 if item is among most popular\n",
    "# method 1 yielded better results, so method 2 is commented out below\n",
    "\n",
    "test_pred_boolean = []  # prediction values (0 or 1)\n",
    "test_pred = []          # interaction score (dot product between user vec and item vec)\n",
    "test_user_item_indices = list(zip(test_data['reviewer_indices'],test_data['item_indices']))\n",
    "\n",
    "for user, item in test_user_item_indices:\n",
    "    if int(user) == 123456:  # for users who did not exist in test set (104 users), set prediction to 1 if item is among most popular\n",
    "        #if int(item) in pop_items:\n",
    "        #    test_pred_boolean.append(1)\n",
    "        #    test_pred.append(0)\n",
    "        #else:\n",
    "            test_pred_boolean.append(0)\n",
    "            test_pred.append(0)\n",
    "    elif int(item) == 123456:   # if item did not exist in the test set, set prediction to 0\n",
    "        test_pred_boolean.append(0)\n",
    "        test_pred.append(0)\n",
    "    else:                      # if user or item did exist in test set...\n",
    "        user_vec = predictions[0][int(user),:]\n",
    "        pred = user_vec.dot(item_vecs).toarray().reshape(-1)\n",
    "        test_pred.append(pred[int(item)])  # generate interaction score\n",
    "        \n",
    "        top_indices = numpy.argsort(pred)[::-1][:top_x_items]   # get top x% items with highest interaction scores\n",
    "        pred2 = numpy.zeros(pred.shape)\n",
    "        for i in top_indices:\n",
    "            pred2[i] = 1\n",
    "        test_pred_boolean.append(pred2[int(item)])  # generate 1's and 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_pred_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert predictions and interaction scores into dataframe\n",
    "test_data['prediction'] = numpy.array(test_pred_boolean,dtype=int)\n",
    "test_data['interaction_score'] = numpy.array(test_pred)\n",
    "\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potentially set a cut-off value to determine prediction, in addition to top x%\n",
    "# if interaction score is >= avg interaction score, set prediction to 1\n",
    "# avg_pred = sum(test_pred) / len(test_pred)\n",
    "# mask = test_data['interaction_score'] >= avg_pred\n",
    "# test_data['prediction'][mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe to match format for kaggle submission\n",
    "test_data['reviewerID-itemID'] = test_data['reviewerID'] + \"-\" + test_data['itemID']\n",
    "predictions_upload = test_data[['reviewerID-itemID', 'prediction']]\n",
    "predictions_upload.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_upload.groupby('prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export prediction file for submission\n",
    "\n",
    "path = \"/Users/dipali/Desktop/CMU MSBA/machine_learning_2/final_project/\"\n",
    "\n",
    "predictions_upload.to_csv(path+\"predictions_test.txt\", index=False, header=True, line_terminator=\"\\n\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Purchase_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
